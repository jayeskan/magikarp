{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######\n",
    "# load data to pandas\n",
    "# train\n",
    "# tune parameters on holdout set\n",
    "# test\n",
    "# kfolds cross validation\n",
    "#######\n",
    "# comparisons:\n",
    "# linear regression\n",
    "# decision trees (random forest via scikit learn)\n",
    "# ff neural network (lin, relu, lin) higher order polyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Imports\n",
    "import pandas as pd\n",
    "from core_insure.assessor.home_assessor import HomeAssessor\n",
    "from ruamel.yaml import YAML\n",
    "import numpy as np\n",
    "import math\n",
    "from torch import nn\n",
    "\n",
    "LABEL_KEY = 'repairAmount'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lisajiang/magikarp/core_insure/venv/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (31,32,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Load data to pandas\n",
    "# This dataset was downloaded from: \n",
    "# https://www.fema.gov/openfema-dataset-individual-assistance-housing-registrants-large-disasters-v1\n",
    "file = open('core_insure/data/IndividualAssistanceHousingRegistrantsLargeDisasters.csv', 'r')\n",
    "pd_data = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns available, y = repairAmount\n",
    "# For now, filter on just numerical data\n",
    "# Later, can convert string columns (embedding, bins, num categories)\n",
    "all_columns = list(pd_data.columns.values)\n",
    "only_numerical_data = pd_data._get_numeric_data()\n",
    "sorted_numerical_df = pd_data.reindex(sorted(only_numerical_data.columns), axis=1)\n",
    "numeric_columns = sorted(sorted_numerical_df.columns.values)\n",
    "# print(list(numeric_columns))\n",
    "\n",
    "# remove all data where repairs were not made\n",
    "final_sorted_df = sorted_numerical_df[sorted_numerical_df[LABEL_KEY].notnull()]\n",
    "\n",
    "# change categorical to -1, 1\n",
    "# final_sorted_df = final_sorted_df.replace(0,-1)\n",
    "final_sorted_df = final_sorted_df.fillna(0)\n",
    "columns = [\n",
    "    'damagedZipCode',\n",
    "    'disasterNumber',\n",
    "    'repairAmount', \n",
    "    'foundationDamageAmount', \n",
    "    'grossIncome', \n",
    "    'householdComposition',\n",
    "    'roofDamageAmount',\n",
    "    'waterLevel'\n",
    "]\n",
    "final_sorted_df = pd.DataFrame(final_sorted_df, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     damagedZipCode  disasterNumber  repairAmount  foundationDamageAmount  \\\n",
      "52            738.0            4339       2578.09                     0.0   \n",
      "57            652.0            4339      15397.22                     0.0   \n",
      "58          32258.0            4337       2164.50                     0.0   \n",
      "70            757.0            4339       4189.79                     0.0   \n",
      "82          34448.0            4337        499.50                     0.0   \n",
      "94            956.0            4339       6048.26                     0.0   \n",
      "128           795.0            4339        139.64                     0.0   \n",
      "152           738.0            4339       2269.65                     0.0   \n",
      "158           703.0            4339       1953.13                     0.0   \n",
      "165           680.0            4339        269.81                     0.0   \n",
      "\n",
      "     grossIncome  householdComposition  roofDamageAmount  waterLevel  \n",
      "52        7080.0                     3            2064.6         0.0  \n",
      "57        8500.0                     1            1984.0         0.0  \n",
      "58       85000.0                     3               0.0         1.0  \n",
      "70        7872.0                     1            1440.0         0.0  \n",
      "82       50000.0                     1               0.0         0.0  \n",
      "94       18984.0                     1            2284.8         0.0  \n",
      "128      19000.0                     7               6.1         0.0  \n",
      "152      50000.0                     5               0.0         0.0  \n",
      "158      25500.0                     2             307.2         0.0  \n",
      "165      82800.0                     2               0.0        17.0  \n"
     ]
    }
   ],
   "source": [
    "print(final_sorted_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing and training methods\n",
    "def value_of_interest(value):\n",
    "    if pd.isna(value):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def get_row_xy(row):\n",
    "    y_label = row[LABEL_KEY] if value_of_interest(row[LABEL_KEY]) else 0\n",
    "    row.drop([LABEL_KEY])\n",
    "    rowiter = row.iteritems()\n",
    "    x_array = [item[1] if value_of_interest(item[1]) else 0 for item in rowiter]\n",
    "    return x_array, y_label\n",
    "\n",
    "def get_all_xy(df):\n",
    "    all_x = []\n",
    "    all_y = []\n",
    "    for row in df.iterrows():\n",
    "        row_contents = row[1]\n",
    "        x, y = get_row_xy(row_contents)\n",
    "        all_x.append(x)\n",
    "        all_y.append([y])\n",
    "    return all_x, all_y\n",
    "    \n",
    "# def train_with_config(linreg_config, df_data):\n",
    "#     epochs = linreg_config.get('epochs')\n",
    "#     epoch_loss = 0\n",
    "#     for epoch in range(epochs):\n",
    "#         for row in df_data.iterrows():\n",
    "#             row_contents = row[1]\n",
    "#             x, y = get_row_xy(row_contents)\n",
    "#             \n",
    "#             y_pred = self.model(self._torch_var(x))\n",
    "#             loss = self.loss(y_pred, self._torch_var(y))\n",
    "#             epoch_loss = loss.data[0]\n",
    "#     \n",
    "#             self.optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             self.optimizer.step()\n",
    "#         print(f'Epoch {epoch} loss: {epoch_loss}')\n",
    "\n",
    "# train_with_config(linreg_config, sorted_numerical_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total test set: 274047\n",
      "Training set: 219237, Testing set: 54810\n",
      "Get training set\n",
      "Get testing set\n"
     ]
    }
   ],
   "source": [
    "# 80-20 Split\n",
    "total_rows = final_sorted_df.shape[0]\n",
    "print(f'Total test set: {total_rows}')\n",
    "train_size = math.floor(total_rows*.80)\n",
    "test_size = total_rows - train_size\n",
    "print(f'Training set: {train_size}, Testing set: {test_size}')\n",
    "\n",
    "train_x, train_y = get_all_xy(final_sorted_df.head(100))\n",
    "print(\"Get training set\")\n",
    "test_x, test_y = get_all_xy(final_sorted_df.tail(10))\n",
    "print(\"Get testing set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ordereddict([('base', ordereddict([('filepath', '.')])), ('assessor', ordereddict([('model', 'linear_regression'), ('linear_regression', ordereddict([('output_size', 1), ('lr', 0.01), ('momentum', 0.001), ('epochs', 500)])), ('simple_nn', ordereddict([('output_size', 1), ('lr', 0.001), ('epochs', 500), ('hidden_size', 50)])), ('filepath', '.')]))])\n"
     ]
    }
   ],
   "source": [
    "# Get config\n",
    "default_config_file = open('core_insure/config.yaml', 'r')\n",
    "yaml = YAML()\n",
    "config = yaml.load(default_config_file)\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 4958.27783203125, y_pred preview: tensor([-121.9391])\n",
      "Epoch 1, Loss: 2335454.25, y_pred preview: tensor([1263215.1250])\n",
      "Epoch 2, Loss: 248054.4375, y_pred preview: tensor([-92960.3828])\n",
      "Epoch 3, Loss: 2335211.0, y_pred preview: tensor([1263122.2500])\n",
      "Epoch 4, Loss: 248054.59375, y_pred preview: tensor([-92960.4297])\n",
      "Epoch 5, Loss: 2335211.0, y_pred preview: tensor([1263122.2500])\n",
      "Epoch 6, Loss: 248054.59375, y_pred preview: tensor([-92960.4297])\n",
      "Epoch 7, Loss: 2335211.0, y_pred preview: tensor([1263122.2500])\n",
      "Epoch 8, Loss: 248054.59375, y_pred preview: tensor([-92960.4297])\n",
      "Epoch 9, Loss: 2335211.0, y_pred preview: tensor([1263122.2500])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "smooth_l1_loss(): argument 'input' (position 1) must be Tensor, not numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-5de12d4f4692>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtrain_pred_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pred_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_torch_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Train Loss: {train_loss}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Test linear regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/magikarp/core_insure/venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/magikarp/core_insure/venv/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmooth_l1_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/magikarp/core_insure/venv/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36msmooth_l1_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   1685\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1686\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1687\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmooth_l1_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: smooth_l1_loss(): argument 'input' (position 1) must be Tensor, not numpy.ndarray"
     ]
    }
   ],
   "source": [
    "# Train linear regression\n",
    "assessor_config =  config['assessor']\n",
    "assessor_config['linear_regression']['epochs'] = 10\n",
    "assessor = HomeAssessor(assessor_config)\n",
    "\n",
    "# exploding gradients?\n",
    "train_output = assessor.train(train_x, train_y)\n",
    "\n",
    "# Train loss \n",
    "model = assessor.model\n",
    "train_pred_y = model.eval(train_x)\n",
    "loss = model.loss\n",
    "train_loss = loss(train_pred_y, model._torch_var(train_y))\n",
    "print(f'Train Loss: {train_loss}')\n",
    "# Test linear regression\n",
    "#pred_y = assessor.eval(test_x)\n",
    "#val_loss = nn.MSELoss(y_pred, y_true)\n",
    "#print(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 2.1970219765740666e+26, y_pred preview: tensor([-15725909508096.])\n",
      "Epoch 1, Loss: 2.1970219765740666e+26, y_pred preview: tensor([-15725909508096.])\n",
      "Epoch 2, Loss: 2.1970219765740666e+26, y_pred preview: tensor([-15725909508096.])\n",
      "Epoch 3, Loss: 2.1970219765740666e+26, y_pred preview: tensor([-15725909508096.])\n",
      "Epoch 4, Loss: 2.1970219765740666e+26, y_pred preview: tensor([-15725909508096.])\n",
      "Epoch 5, Loss: 2.1970219765740666e+26, y_pred preview: tensor([-15725909508096.])\n",
      "Epoch 6, Loss: 2.1970219765740666e+26, y_pred preview: tensor([-15725909508096.])\n",
      "Epoch 7, Loss: 2.1970219765740666e+26, y_pred preview: tensor([-15725909508096.])\n",
      "Epoch 8, Loss: 2.1970219765740666e+26, y_pred preview: tensor([-15725909508096.])\n",
      "Epoch 9, Loss: 2.1970219765740666e+26, y_pred preview: tensor([-15725909508096.])\n"
     ]
    }
   ],
   "source": [
    "# Train nn module\n",
    "assessor_config =  config['assessor']\n",
    "assessor_config['simple_nn']['epochs'] = 10\n",
    "assessor_config['model'] = 'simple_nn'\n",
    "assessor = HomeAssessor(assessor_config)\n",
    "\n",
    "train_output = assessor.train(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
