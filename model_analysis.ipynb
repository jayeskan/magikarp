{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######\n",
    "# load data to pandas\n",
    "# train\n",
    "# tune parameters on holdout set\n",
    "# test\n",
    "# kfolds cross validation\n",
    "#######\n",
    "# comparisons:\n",
    "# linear regression\n",
    "# decision trees (random forest via scikit learn)\n",
    "# ff neural network (lin, relu, lin) higher order polyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Imports\n",
    "import pandas as pd\n",
    "from core_insure.assessor.home_assessor import HomeAssessor\n",
    "from ruamel.yaml import YAML\n",
    "import numpy as np\n",
    "import math\n",
    "from torch import nn\n",
    "\n",
    "LABEL_KEY = 'claimAmount'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing and training methods\n",
    "def value_of_interest(value):\n",
    "    if pd.isna(value):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def get_row_xy(row):\n",
    "    y_label = row[LABEL_KEY] if value_of_interest(row[LABEL_KEY]) else 0\n",
    "    row = row.drop([LABEL_KEY])\n",
    "    rowiter = row.iteritems()\n",
    "    x_array = [item[1] if value_of_interest(item[1]) else 0 for item in rowiter]\n",
    "    return x_array, y_label\n",
    "\n",
    "def get_all_xy(df):\n",
    "    all_x = []\n",
    "    all_y = []\n",
    "    for row in df.iterrows():\n",
    "        row_contents = row[1]\n",
    "        x, y = get_row_xy(row_contents)\n",
    "        all_x.append(x)\n",
    "        all_y.append([y])\n",
    "    return all_x, all_y\n",
    "\n",
    "def calculate_train_val_loss(curr_assessor, train_x, train_y, test_x, test_y):\n",
    "    # exploding gradients?\n",
    "    train_output = curr_assessor.train(train_x, train_y)\n",
    "\n",
    "    # Train loss \n",
    "    model = curr_assessor.model\n",
    "    train_pred_y = model.eval(train_x)\n",
    "    loss = model.loss\n",
    "    train_loss = loss(model._torch_var(train_pred_y), model._torch_var(train_y))\n",
    "    print(f'Train Loss: {train_loss}')\n",
    "    \n",
    "    # Test linear regression\n",
    "    test_y_pred = model.eval(test_x)\n",
    "    test_loss = loss(model._torch_var(test_y_pred), model._torch_var(test_y))\n",
    "    print(f'Test Losss: {test_loss}')\n",
    "    \n",
    "    return train_loss, test_loss\n",
    "\n",
    "def train_test_split(df, train_percent, test_percent):\n",
    "    total_rows = df.shape[0]\n",
    "    print(f'Total test set: {total_rows}')\n",
    "    train_size = math.floor(total_rows*(train_percent/100))\n",
    "    test_size = total_rows - train_size\n",
    "    print(f'Training set: {train_size}, Testing set: {test_size}')\n",
    "    train_x, train_y = get_all_xy(final_sorted_df.head(train_size))\n",
    "    print(f'Train set created')\n",
    "    test_x, test_y = get_all_xy(final_sorted_df.tail(test_size))\n",
    "    print(f'Test set created')\n",
    "    return {\n",
    "        'train_x': train_x,\n",
    "        'train_y': train_y,\n",
    "        'test_x': test_x,\n",
    "        'test_y': test_y\n",
    "    }\n",
    "\n",
    "# def train_with_config(linreg_config, df_data):\n",
    "#     epochs = linreg_config.get('epochs')\n",
    "#     epoch_loss = 0\n",
    "#     for epoch in range(epochs):\n",
    "#         for row in df_data.iterrows():\n",
    "#             row_contents = row[1]\n",
    "#             x, y = get_row_xy(row_contents)\n",
    "#             \n",
    "#             y_pred = self.model(self._torch_var(x))\n",
    "#             loss = self.loss(y_pred, self._torch_var(y))\n",
    "#             epoch_loss = loss.data[0]\n",
    "#     \n",
    "#             self.optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             self.optimizer.step()\n",
    "#         print(f'Epoch {epoch} loss: {epoch_loss}')\n",
    "\n",
    "# train_with_config(linreg_config, sorted_numerical_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lisajiang/magikarp/core_insure/venv/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (31,32,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Load data to pandas\n",
    "# This dataset was downloaded from: \n",
    "# https://www.fema.gov/openfema-dataset-individual-assistance-housing-registrants-large-disasters-v1\n",
    "file = open('core_insure/data/IndividualAssistanceHousingRegistrantsLargeDisasters.csv', 'r')\n",
    "pd_data = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ordereddict([('base', ordereddict([('filepath', '.')])), ('assessor', ordereddict([('model', 'linear_regression'), ('linear_regression', ordereddict([('output_size', 1), ('lr', 1e-05), ('momentum', 0), ('epochs', 500)])), ('simple_nn', ordereddict([('output_size', 1), ('lr', 0.001), ('epochs', 500), ('hidden_size', 50)])), ('filepath', '.')]))])\n"
     ]
    }
   ],
   "source": [
    "# Get config\n",
    "default_config_file = open('core_insure/config.yaml', 'r')\n",
    "yaml = YAML()\n",
    "config = yaml.load(default_config_file)\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['censusBlockId', 'censusYear', 'claimAmount', 'damagedZipCode', 'destroyed', 'disasterNumber', 'floodDamage', 'floodInsurance', 'foundationDamage', 'foundationDamageAmount', 'grossIncome', 'habitabilityRepairsRequired', 'homeOwnersInsurance', 'householdComposition', 'inspected', 'personalPropertyEligible', 'ppfvl', 'primaryResidence', 'rentalAssistanceAmount', 'rentalAssistanceEligible', 'rentalResourceZipCode', 'repairAmount', 'repairAssistanceEligible', 'replacementAmount', 'replacementAssistanceEligible', 'roofDamage', 'roofDamageAmount', 'rpfvl', 'sbaEligible', 'specialNeeds', 'tsaCheckedIn', 'tsaEligible', 'waterLevel']\n"
     ]
    }
   ],
   "source": [
    "# Data processing\n",
    "# Columns available\n",
    "all_columns = list(pd_data.columns.values)\n",
    "\n",
    "# calculate label: claimAmount based on repairs and replacements\n",
    "pd_data = pd_data.fillna(0)\n",
    "pd_data[LABEL_KEY] = pd_data['repairAmount'] + pd_data['replacementAmount']\n",
    "\n",
    "# For now, filter on just numerical data\n",
    "# Later, can convert string columns (embedding, bins, num categories)\n",
    "only_numerical_data = pd_data._get_numeric_data()\n",
    "sorted_numerical_df = pd_data.reindex(sorted(only_numerical_data.columns), axis=1)\n",
    "numeric_columns = sorted(sorted_numerical_df.columns.values)\n",
    "print(list(numeric_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all data where repairs were not made\n",
    "nonzero_numerical_df = sorted_numerical_df.replace(0, np.nan)\n",
    "nonzero_numerical_df = nonzero_numerical_df[sorted_numerical_df[LABEL_KEY].notnull()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   repairAmount  claimAmount\n",
      "0           0.0          0.0\n",
      "1           0.0          0.0\n",
      "2           0.0          0.0\n",
      "3           0.0          0.0\n",
      "4           0.0          0.0\n",
      "5           0.0          0.0\n",
      "6           0.0          0.0\n",
      "7           0.0          0.0\n",
      "8           0.0          0.0\n",
      "9           0.0          0.0\n"
     ]
    }
   ],
   "source": [
    "# Feature Extraction\n",
    "# columns = [\n",
    "#     'damagedZipCode',\n",
    "#     'disasterNumber',\n",
    "#     'foundationDamageAmount', \n",
    "#     'grossIncome', \n",
    "#     'householdComposition',\n",
    "#     'roofDamageAmount',\n",
    "#     'waterLevel',\n",
    "#     LABEL_KEY\n",
    "# ]\n",
    "columns = [\n",
    "    'repairAmount',\n",
    "    LABEL_KEY\n",
    "]\n",
    "\n",
    "final_sorted_df = pd.DataFrame(sorted_numerical_df, columns=columns)\n",
    "final_sorted_df = final_sorted_df.replace(np.nan,0)\n",
    "\n",
    "# final_sorted_df = sorted_numerical_df[sorted_numerical_df['repairAmount'].notnull()] \n",
    "# final_sorted_df = final_sorted_df.replace(0,1)\n",
    "print(final_sorted_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total test set: 1000\n",
      "Training set: 800, Testing set: 200\n"
     ]
    }
   ],
   "source": [
    "# 80-20 Split\n",
    "# full_dataset = final_sorted_df\n",
    "full_dataset = final_sorted_df.head(1000)\n",
    "train_test_dataset = train_test_split(full_dataset, 80, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 575.173095703125, y_pred preview: tensor([0.2446])\n",
      "Epoch 1, Loss: 574.6365356445312, y_pred preview: tensor([0.2446])\n",
      "Epoch 2, Loss: 574.0999755859375, y_pred preview: tensor([0.2446])\n",
      "Epoch 3, Loss: 573.5633544921875, y_pred preview: tensor([0.2446])\n",
      "Epoch 4, Loss: 573.0267333984375, y_pred preview: tensor([0.2446])\n",
      "Epoch 5, Loss: 572.4902954101562, y_pred preview: tensor([0.2446])\n",
      "Epoch 6, Loss: 571.9535522460938, y_pred preview: tensor([0.2446])\n",
      "Epoch 7, Loss: 571.4169921875, y_pred preview: tensor([0.2446])\n",
      "Epoch 8, Loss: 570.8803100585938, y_pred preview: tensor([0.2446])\n",
      "Epoch 9, Loss: 570.3436889648438, y_pred preview: tensor([0.2446])\n",
      "Epoch 10, Loss: 569.80712890625, y_pred preview: tensor([0.2446])\n",
      "Epoch 11, Loss: 569.2705078125, y_pred preview: tensor([0.2446])\n",
      "Epoch 12, Loss: 568.7339477539062, y_pred preview: tensor([0.2446])\n",
      "Epoch 13, Loss: 568.1973266601562, y_pred preview: tensor([0.2446])\n",
      "Epoch 14, Loss: 567.6607055664062, y_pred preview: tensor([0.2446])\n",
      "Epoch 15, Loss: 567.1240844726562, y_pred preview: tensor([0.2446])\n",
      "Epoch 16, Loss: 566.5874633789062, y_pred preview: tensor([0.2446])\n",
      "Epoch 17, Loss: 566.0508422851562, y_pred preview: tensor([0.2446])\n",
      "Epoch 18, Loss: 565.5142822265625, y_pred preview: tensor([0.2446])\n",
      "Epoch 19, Loss: 564.9777221679688, y_pred preview: tensor([0.2446])\n",
      "Epoch 20, Loss: 564.4410400390625, y_pred preview: tensor([0.2446])\n",
      "Epoch 21, Loss: 563.9044799804688, y_pred preview: tensor([0.2446])\n",
      "Epoch 22, Loss: 563.3677978515625, y_pred preview: tensor([0.2446])\n",
      "Epoch 23, Loss: 562.8312377929688, y_pred preview: tensor([0.2446])\n",
      "Epoch 24, Loss: 562.2945556640625, y_pred preview: tensor([0.2446])\n",
      "Epoch 25, Loss: 561.7579956054688, y_pred preview: tensor([0.2446])\n",
      "Epoch 26, Loss: 561.2213745117188, y_pred preview: tensor([0.2446])\n",
      "Epoch 27, Loss: 560.6847534179688, y_pred preview: tensor([0.2446])\n",
      "Epoch 28, Loss: 560.148193359375, y_pred preview: tensor([0.2446])\n",
      "Epoch 29, Loss: 559.6115112304688, y_pred preview: tensor([0.2446])\n",
      "Epoch 30, Loss: 559.074951171875, y_pred preview: tensor([0.2446])\n",
      "Epoch 31, Loss: 558.5384521484375, y_pred preview: tensor([0.2446])\n",
      "Epoch 32, Loss: 558.001708984375, y_pred preview: tensor([0.2446])\n",
      "Epoch 33, Loss: 557.465087890625, y_pred preview: tensor([0.2446])\n",
      "Epoch 34, Loss: 556.9284057617188, y_pred preview: tensor([0.2446])\n",
      "Epoch 35, Loss: 556.3919067382812, y_pred preview: tensor([0.2446])\n",
      "Epoch 36, Loss: 555.8552856445312, y_pred preview: tensor([0.2446])\n",
      "Epoch 37, Loss: 555.3186645507812, y_pred preview: tensor([0.2446])\n",
      "Epoch 38, Loss: 554.7821044921875, y_pred preview: tensor([0.2446])\n",
      "Epoch 39, Loss: 554.2454833984375, y_pred preview: tensor([0.2446])\n",
      "Epoch 40, Loss: 553.7088623046875, y_pred preview: tensor([0.2446])\n",
      "Epoch 41, Loss: 553.1723022460938, y_pred preview: tensor([0.2446])\n",
      "Epoch 42, Loss: 552.6356811523438, y_pred preview: tensor([0.2446])\n",
      "Epoch 43, Loss: 552.09912109375, y_pred preview: tensor([0.2446])\n",
      "Epoch 44, Loss: 551.5623779296875, y_pred preview: tensor([0.2446])\n",
      "Epoch 45, Loss: 551.0259399414062, y_pred preview: tensor([0.2446])\n",
      "Epoch 46, Loss: 550.4891967773438, y_pred preview: tensor([0.2446])\n",
      "Epoch 47, Loss: 549.9526977539062, y_pred preview: tensor([0.2446])\n",
      "Epoch 48, Loss: 549.4160766601562, y_pred preview: tensor([0.2446])\n",
      "Epoch 49, Loss: 548.87939453125, y_pred preview: tensor([0.2446])\n",
      "Epoch 50, Loss: 548.3428344726562, y_pred preview: tensor([0.2446])\n",
      "Epoch 51, Loss: 547.8062744140625, y_pred preview: tensor([0.2446])\n",
      "Epoch 52, Loss: 547.26953125, y_pred preview: tensor([0.2446])\n",
      "Epoch 53, Loss: 546.7328491210938, y_pred preview: tensor([0.2446])\n",
      "Epoch 54, Loss: 546.1964111328125, y_pred preview: tensor([0.2446])\n",
      "Epoch 55, Loss: 545.6597290039062, y_pred preview: tensor([0.2446])\n",
      "Epoch 56, Loss: 545.1232299804688, y_pred preview: tensor([0.2445])\n",
      "Epoch 57, Loss: 544.5866088867188, y_pred preview: tensor([0.2445])\n",
      "Epoch 58, Loss: 544.050048828125, y_pred preview: tensor([0.2445])\n",
      "Epoch 59, Loss: 543.5133666992188, y_pred preview: tensor([0.2445])\n",
      "Epoch 60, Loss: 542.9766845703125, y_pred preview: tensor([0.2445])\n",
      "Epoch 61, Loss: 542.4401245117188, y_pred preview: tensor([0.2445])\n",
      "Epoch 62, Loss: 541.903564453125, y_pred preview: tensor([0.2445])\n",
      "Epoch 63, Loss: 541.3670043945312, y_pred preview: tensor([0.2445])\n",
      "Epoch 64, Loss: 540.8304443359375, y_pred preview: tensor([0.2445])\n",
      "Epoch 65, Loss: 540.2937622070312, y_pred preview: tensor([0.2445])\n",
      "Epoch 66, Loss: 539.7571411132812, y_pred preview: tensor([0.2445])\n",
      "Epoch 67, Loss: 539.2205200195312, y_pred preview: tensor([0.2445])\n",
      "Epoch 68, Loss: 538.6839599609375, y_pred preview: tensor([0.2445])\n",
      "Epoch 69, Loss: 538.1473388671875, y_pred preview: tensor([0.2445])\n",
      "Epoch 70, Loss: 537.6107788085938, y_pred preview: tensor([0.2445])\n",
      "Epoch 71, Loss: 537.0741577148438, y_pred preview: tensor([0.2445])\n",
      "Epoch 72, Loss: 536.5375366210938, y_pred preview: tensor([0.2445])\n",
      "Epoch 73, Loss: 536.0009155273438, y_pred preview: tensor([0.2445])\n",
      "Epoch 74, Loss: 535.4642333984375, y_pred preview: tensor([0.2445])\n",
      "Epoch 75, Loss: 534.927734375, y_pred preview: tensor([0.2445])\n",
      "Epoch 76, Loss: 534.39111328125, y_pred preview: tensor([0.2445])\n",
      "Epoch 77, Loss: 533.8545532226562, y_pred preview: tensor([0.2445])\n",
      "Epoch 78, Loss: 533.31787109375, y_pred preview: tensor([0.2445])\n",
      "Epoch 79, Loss: 532.7813110351562, y_pred preview: tensor([0.2445])\n",
      "Epoch 80, Loss: 532.24462890625, y_pred preview: tensor([0.2445])\n",
      "Epoch 81, Loss: 531.7080688476562, y_pred preview: tensor([0.2445])\n",
      "Epoch 82, Loss: 531.1715087890625, y_pred preview: tensor([0.2445])\n",
      "Epoch 83, Loss: 530.6348266601562, y_pred preview: tensor([0.2445])\n",
      "Epoch 84, Loss: 530.0982666015625, y_pred preview: tensor([0.2445])\n",
      "Epoch 85, Loss: 529.561767578125, y_pred preview: tensor([0.2445])\n",
      "Epoch 86, Loss: 529.025146484375, y_pred preview: tensor([0.2445])\n",
      "Epoch 87, Loss: 528.4884643554688, y_pred preview: tensor([0.2445])\n",
      "Epoch 88, Loss: 527.9518432617188, y_pred preview: tensor([0.2445])\n",
      "Epoch 89, Loss: 527.4152221679688, y_pred preview: tensor([0.2445])\n",
      "Epoch 90, Loss: 526.8785400390625, y_pred preview: tensor([0.2445])\n",
      "Epoch 91, Loss: 526.3419799804688, y_pred preview: tensor([0.2445])\n",
      "Epoch 92, Loss: 525.8053588867188, y_pred preview: tensor([0.2445])\n",
      "Epoch 93, Loss: 525.268798828125, y_pred preview: tensor([0.2445])\n",
      "Epoch 94, Loss: 524.7322387695312, y_pred preview: tensor([0.2445])\n",
      "Epoch 95, Loss: 524.1954956054688, y_pred preview: tensor([0.2445])\n",
      "Epoch 96, Loss: 523.658935546875, y_pred preview: tensor([0.2445])\n",
      "Epoch 97, Loss: 523.122314453125, y_pred preview: tensor([0.2445])\n",
      "Epoch 98, Loss: 522.5857543945312, y_pred preview: tensor([0.2445])\n",
      "Epoch 99, Loss: 522.049072265625, y_pred preview: tensor([0.2445])\n",
      "Epoch 100, Loss: 521.5125122070312, y_pred preview: tensor([0.2445])\n",
      "Epoch 101, Loss: 520.9758911132812, y_pred preview: tensor([0.2445])\n",
      "Epoch 102, Loss: 520.4393310546875, y_pred preview: tensor([0.2445])\n",
      "Epoch 103, Loss: 519.9027709960938, y_pred preview: tensor([0.2445])\n",
      "Epoch 104, Loss: 519.3660888671875, y_pred preview: tensor([0.2445])\n",
      "Epoch 105, Loss: 518.8294677734375, y_pred preview: tensor([0.2445])\n",
      "Epoch 106, Loss: 518.2928466796875, y_pred preview: tensor([0.2445])\n",
      "Epoch 107, Loss: 517.7562255859375, y_pred preview: tensor([0.2445])\n",
      "Epoch 108, Loss: 517.2196655273438, y_pred preview: tensor([0.2445])\n",
      "Epoch 109, Loss: 516.6830444335938, y_pred preview: tensor([0.2445])\n",
      "Epoch 110, Loss: 516.146484375, y_pred preview: tensor([0.2445])\n",
      "Epoch 111, Loss: 515.6099853515625, y_pred preview: tensor([0.2445])\n",
      "Epoch 112, Loss: 515.0733032226562, y_pred preview: tensor([0.2445])\n",
      "Epoch 113, Loss: 514.5366821289062, y_pred preview: tensor([0.2445])\n",
      "Epoch 114, Loss: 514.0001220703125, y_pred preview: tensor([0.2445])\n",
      "Epoch 115, Loss: 513.4635009765625, y_pred preview: tensor([0.2445])\n",
      "Epoch 116, Loss: 512.9268188476562, y_pred preview: tensor([0.2445])\n",
      "Epoch 117, Loss: 512.3903198242188, y_pred preview: tensor([0.2445])\n",
      "Epoch 118, Loss: 511.8536376953125, y_pred preview: tensor([0.2445])\n",
      "Epoch 119, Loss: 511.3169860839844, y_pred preview: tensor([0.2445])\n",
      "Epoch 120, Loss: 510.7804260253906, y_pred preview: tensor([0.2444])\n",
      "Epoch 121, Loss: 510.2437744140625, y_pred preview: tensor([0.2444])\n",
      "Epoch 122, Loss: 509.707275390625, y_pred preview: tensor([0.2444])\n",
      "Epoch 123, Loss: 509.1705322265625, y_pred preview: tensor([0.2444])\n",
      "Epoch 124, Loss: 508.63397216796875, y_pred preview: tensor([0.2444])\n",
      "Epoch 125, Loss: 508.0972900390625, y_pred preview: tensor([0.2444])\n",
      "Epoch 126, Loss: 507.5606994628906, y_pred preview: tensor([0.2444])\n",
      "Epoch 127, Loss: 507.02423095703125, y_pred preview: tensor([0.2444])\n",
      "Epoch 128, Loss: 506.487548828125, y_pred preview: tensor([0.2444])\n",
      "Epoch 129, Loss: 505.9508972167969, y_pred preview: tensor([0.2444])\n",
      "Epoch 130, Loss: 505.41436767578125, y_pred preview: tensor([0.2444])\n",
      "Epoch 131, Loss: 504.8776550292969, y_pred preview: tensor([0.2444])\n",
      "Epoch 132, Loss: 504.3410949707031, y_pred preview: tensor([0.2444])\n",
      "Epoch 133, Loss: 503.804443359375, y_pred preview: tensor([0.2444])\n",
      "Epoch 134, Loss: 503.26776123046875, y_pred preview: tensor([0.2444])\n",
      "Epoch 135, Loss: 502.7312927246094, y_pred preview: tensor([0.2444])\n",
      "Epoch 136, Loss: 502.1947021484375, y_pred preview: tensor([0.2444])\n",
      "Epoch 137, Loss: 501.6580810546875, y_pred preview: tensor([0.2444])\n",
      "Epoch 138, Loss: 501.1214904785156, y_pred preview: tensor([0.2444])\n",
      "Epoch 139, Loss: 500.5848693847656, y_pred preview: tensor([0.2444])\n",
      "Epoch 140, Loss: 500.0482482910156, y_pred preview: tensor([0.2444])\n",
      "Epoch 141, Loss: 499.5116882324219, y_pred preview: tensor([0.2444])\n",
      "Epoch 142, Loss: 498.9750671386719, y_pred preview: tensor([0.2444])\n",
      "Epoch 143, Loss: 498.4384765625, y_pred preview: tensor([0.2444])\n",
      "Epoch 144, Loss: 497.9018249511719, y_pred preview: tensor([0.2444])\n",
      "Epoch 145, Loss: 497.3653259277344, y_pred preview: tensor([0.2444])\n",
      "Epoch 146, Loss: 496.8285827636719, y_pred preview: tensor([0.2444])\n",
      "Epoch 147, Loss: 496.2920227050781, y_pred preview: tensor([0.2444])\n",
      "Epoch 148, Loss: 495.75543212890625, y_pred preview: tensor([0.2444])\n",
      "Epoch 149, Loss: 495.2188720703125, y_pred preview: tensor([0.2444])\n",
      "Epoch 150, Loss: 494.68231201171875, y_pred preview: tensor([0.2444])\n",
      "Epoch 151, Loss: 494.1456298828125, y_pred preview: tensor([0.2444])\n",
      "Epoch 152, Loss: 493.6089782714844, y_pred preview: tensor([0.2444])\n",
      "Epoch 153, Loss: 493.0724182128906, y_pred preview: tensor([0.2444])\n",
      "Epoch 154, Loss: 492.53570556640625, y_pred preview: tensor([0.2444])\n",
      "Epoch 155, Loss: 491.9991760253906, y_pred preview: tensor([0.2444])\n",
      "Epoch 156, Loss: 491.46258544921875, y_pred preview: tensor([0.2444])\n",
      "Epoch 157, Loss: 490.92596435546875, y_pred preview: tensor([0.2444])\n",
      "Epoch 158, Loss: 490.38934326171875, y_pred preview: tensor([0.2444])\n",
      "Epoch 159, Loss: 489.85272216796875, y_pred preview: tensor([0.2444])\n",
      "Epoch 160, Loss: 489.31610107421875, y_pred preview: tensor([0.2444])\n",
      "Epoch 161, Loss: 488.779541015625, y_pred preview: tensor([0.2444])\n",
      "Epoch 162, Loss: 488.242919921875, y_pred preview: tensor([0.2444])\n",
      "Epoch 163, Loss: 487.70635986328125, y_pred preview: tensor([0.2444])\n",
      "Epoch 164, Loss: 487.169677734375, y_pred preview: tensor([0.2444])\n",
      "Epoch 165, Loss: 486.633056640625, y_pred preview: tensor([0.2444])\n",
      "Epoch 166, Loss: 486.0965270996094, y_pred preview: tensor([0.2444])\n",
      "Epoch 167, Loss: 485.559814453125, y_pred preview: tensor([0.2444])\n",
      "Epoch 168, Loss: 485.0233459472656, y_pred preview: tensor([0.2444])\n",
      "Epoch 169, Loss: 484.4867248535156, y_pred preview: tensor([0.2444])\n",
      "Epoch 170, Loss: 483.9500732421875, y_pred preview: tensor([0.2444])\n",
      "Epoch 171, Loss: 483.4134521484375, y_pred preview: tensor([0.2444])\n",
      "Epoch 172, Loss: 482.8768005371094, y_pred preview: tensor([0.2444])\n",
      "Epoch 173, Loss: 482.34027099609375, y_pred preview: tensor([0.2444])\n",
      "Epoch 174, Loss: 481.8036804199219, y_pred preview: tensor([0.2444])\n",
      "Epoch 175, Loss: 481.2670593261719, y_pred preview: tensor([0.2444])\n",
      "Epoch 176, Loss: 480.7305603027344, y_pred preview: tensor([0.2444])\n",
      "Epoch 177, Loss: 480.1939392089844, y_pred preview: tensor([0.2444])\n",
      "Epoch 178, Loss: 479.6572570800781, y_pred preview: tensor([0.2444])\n",
      "Epoch 179, Loss: 479.1206359863281, y_pred preview: tensor([0.2444])\n",
      "Epoch 180, Loss: 478.583984375, y_pred preview: tensor([0.2444])\n",
      "Epoch 181, Loss: 478.04742431640625, y_pred preview: tensor([0.2444])\n",
      "Epoch 182, Loss: 477.5107727050781, y_pred preview: tensor([0.2444])\n",
      "Epoch 183, Loss: 476.9742431640625, y_pred preview: tensor([0.2444])\n",
      "Epoch 184, Loss: 476.4376525878906, y_pred preview: tensor([0.2443])\n",
      "Epoch 185, Loss: 475.9010009765625, y_pred preview: tensor([0.2443])\n",
      "Epoch 186, Loss: 475.3643798828125, y_pred preview: tensor([0.2443])\n",
      "Epoch 187, Loss: 474.82781982421875, y_pred preview: tensor([0.2443])\n",
      "Epoch 188, Loss: 474.2911376953125, y_pred preview: tensor([0.2443])\n",
      "Epoch 189, Loss: 473.7546081542969, y_pred preview: tensor([0.2443])\n",
      "Epoch 190, Loss: 473.21795654296875, y_pred preview: tensor([0.2443])\n",
      "Epoch 191, Loss: 472.68133544921875, y_pred preview: tensor([0.2443])\n",
      "Epoch 192, Loss: 472.144775390625, y_pred preview: tensor([0.2443])\n",
      "Epoch 193, Loss: 471.60809326171875, y_pred preview: tensor([0.2443])\n",
      "Epoch 194, Loss: 471.071533203125, y_pred preview: tensor([0.2443])\n",
      "Epoch 195, Loss: 470.5348815917969, y_pred preview: tensor([0.2443])\n",
      "Epoch 196, Loss: 469.99835205078125, y_pred preview: tensor([0.2443])\n",
      "Epoch 197, Loss: 469.4616394042969, y_pred preview: tensor([0.2443])\n",
      "Epoch 198, Loss: 468.9250793457031, y_pred preview: tensor([0.2443])\n",
      "Epoch 199, Loss: 468.388427734375, y_pred preview: tensor([0.2443])\n",
      "Epoch 200, Loss: 467.851806640625, y_pred preview: tensor([0.2443])\n",
      "Epoch 201, Loss: 467.3152770996094, y_pred preview: tensor([0.2443])\n",
      "Epoch 202, Loss: 466.77862548828125, y_pred preview: tensor([0.2443])\n",
      "Epoch 203, Loss: 466.2420349121094, y_pred preview: tensor([0.2443])\n",
      "Epoch 204, Loss: 465.7054748535156, y_pred preview: tensor([0.2443])\n",
      "Epoch 205, Loss: 465.1689147949219, y_pred preview: tensor([0.2443])\n",
      "Epoch 206, Loss: 464.6322326660156, y_pred preview: tensor([0.2443])\n",
      "Epoch 207, Loss: 464.0955505371094, y_pred preview: tensor([0.2443])\n",
      "Epoch 208, Loss: 463.5589904785156, y_pred preview: tensor([0.2443])\n",
      "Epoch 209, Loss: 463.0223693847656, y_pred preview: tensor([0.2443])\n",
      "Epoch 210, Loss: 462.4858093261719, y_pred preview: tensor([0.2443])\n",
      "Epoch 211, Loss: 461.94921875, y_pred preview: tensor([0.2443])\n",
      "Epoch 212, Loss: 461.4125671386719, y_pred preview: tensor([0.2443])\n",
      "Epoch 213, Loss: 460.8760681152344, y_pred preview: tensor([0.2443])\n",
      "Epoch 214, Loss: 460.3393249511719, y_pred preview: tensor([0.2443])\n",
      "Epoch 215, Loss: 459.8027648925781, y_pred preview: tensor([0.2443])\n",
      "Epoch 216, Loss: 459.2662048339844, y_pred preview: tensor([0.2443])\n",
      "Epoch 217, Loss: 458.7296447753906, y_pred preview: tensor([0.2443])\n",
      "Epoch 218, Loss: 458.1929626464844, y_pred preview: tensor([0.2443])\n",
      "Epoch 219, Loss: 457.6564025878906, y_pred preview: tensor([0.2443])\n",
      "Epoch 220, Loss: 457.1197204589844, y_pred preview: tensor([0.2443])\n",
      "Epoch 221, Loss: 456.5830993652344, y_pred preview: tensor([0.2443])\n",
      "Epoch 222, Loss: 456.0464782714844, y_pred preview: tensor([0.2443])\n",
      "Epoch 223, Loss: 455.5099182128906, y_pred preview: tensor([0.2443])\n",
      "Epoch 224, Loss: 454.97332763671875, y_pred preview: tensor([0.2443])\n",
      "Epoch 225, Loss: 454.436767578125, y_pred preview: tensor([0.2443])\n",
      "Epoch 226, Loss: 453.900146484375, y_pred preview: tensor([0.2443])\n",
      "Epoch 227, Loss: 453.36346435546875, y_pred preview: tensor([0.2443])\n",
      "Epoch 228, Loss: 452.82684326171875, y_pred preview: tensor([0.2443])\n",
      "Epoch 229, Loss: 452.29034423828125, y_pred preview: tensor([0.2443])\n",
      "Epoch 230, Loss: 451.7536315917969, y_pred preview: tensor([0.2443])\n",
      "Epoch 231, Loss: 451.217041015625, y_pred preview: tensor([0.2443])\n",
      "Epoch 232, Loss: 450.680419921875, y_pred preview: tensor([0.2443])\n",
      "Epoch 233, Loss: 450.14373779296875, y_pred preview: tensor([0.2443])\n",
      "Epoch 234, Loss: 449.60723876953125, y_pred preview: tensor([0.2443])\n",
      "Epoch 235, Loss: 449.0705871582031, y_pred preview: tensor([0.2443])\n",
      "Epoch 236, Loss: 448.5340576171875, y_pred preview: tensor([0.2443])\n",
      "Epoch 237, Loss: 447.99737548828125, y_pred preview: tensor([0.2443])\n",
      "Epoch 238, Loss: 447.46075439453125, y_pred preview: tensor([0.2443])\n",
      "Epoch 239, Loss: 446.92413330078125, y_pred preview: tensor([0.2443])\n",
      "Epoch 240, Loss: 446.3875732421875, y_pred preview: tensor([0.2443])\n",
      "Epoch 241, Loss: 445.85101318359375, y_pred preview: tensor([0.2443])\n",
      "Epoch 242, Loss: 445.3144836425781, y_pred preview: tensor([0.2443])\n",
      "Epoch 243, Loss: 444.7778015136719, y_pred preview: tensor([0.2443])\n",
      "Epoch 244, Loss: 444.2413330078125, y_pred preview: tensor([0.2443])\n",
      "Epoch 245, Loss: 443.7046813964844, y_pred preview: tensor([0.2443])\n",
      "Epoch 246, Loss: 443.16796875, y_pred preview: tensor([0.2443])\n",
      "Epoch 247, Loss: 442.6314392089844, y_pred preview: tensor([0.2443])\n",
      "Epoch 248, Loss: 442.0946960449219, y_pred preview: tensor([0.2443])\n",
      "Epoch 249, Loss: 441.5581970214844, y_pred preview: tensor([0.2442])\n",
      "Epoch 250, Loss: 441.0216064453125, y_pred preview: tensor([0.2442])\n",
      "Epoch 251, Loss: 440.4849853515625, y_pred preview: tensor([0.2442])\n",
      "Epoch 252, Loss: 439.94842529296875, y_pred preview: tensor([0.2442])\n",
      "Epoch 253, Loss: 439.41180419921875, y_pred preview: tensor([0.2442])\n",
      "Epoch 254, Loss: 438.8751220703125, y_pred preview: tensor([0.2442])\n",
      "Epoch 255, Loss: 438.33856201171875, y_pred preview: tensor([0.2442])\n",
      "Epoch 256, Loss: 437.8019104003906, y_pred preview: tensor([0.2442])\n",
      "Epoch 257, Loss: 437.2653503417969, y_pred preview: tensor([0.2442])\n",
      "Epoch 258, Loss: 436.7286682128906, y_pred preview: tensor([0.2442])\n",
      "Epoch 259, Loss: 436.1921081542969, y_pred preview: tensor([0.2442])\n",
      "Epoch 260, Loss: 435.65557861328125, y_pred preview: tensor([0.2442])\n",
      "Epoch 261, Loss: 435.1188659667969, y_pred preview: tensor([0.2442])\n",
      "Epoch 262, Loss: 434.5823059082031, y_pred preview: tensor([0.2442])\n",
      "Epoch 263, Loss: 434.045654296875, y_pred preview: tensor([0.2442])\n",
      "Epoch 264, Loss: 433.509033203125, y_pred preview: tensor([0.2442])\n",
      "Epoch 265, Loss: 432.97247314453125, y_pred preview: tensor([0.2442])\n",
      "Epoch 266, Loss: 432.435791015625, y_pred preview: tensor([0.2442])\n",
      "Epoch 267, Loss: 431.8991394042969, y_pred preview: tensor([0.2442])\n",
      "Epoch 268, Loss: 431.3627014160156, y_pred preview: tensor([0.2442])\n",
      "Epoch 269, Loss: 430.8260498046875, y_pred preview: tensor([0.2442])\n",
      "Epoch 270, Loss: 430.28948974609375, y_pred preview: tensor([0.2442])\n",
      "Epoch 271, Loss: 429.7528381347656, y_pred preview: tensor([0.2442])\n",
      "Epoch 272, Loss: 429.2162170410156, y_pred preview: tensor([0.2442])\n",
      "Epoch 273, Loss: 428.6796569824219, y_pred preview: tensor([0.2442])\n",
      "Epoch 274, Loss: 428.1429748535156, y_pred preview: tensor([0.2442])\n",
      "Epoch 275, Loss: 427.6064758300781, y_pred preview: tensor([0.2442])\n",
      "Epoch 276, Loss: 427.0697937011719, y_pred preview: tensor([0.2442])\n",
      "Epoch 277, Loss: 426.5331115722656, y_pred preview: tensor([0.2442])\n",
      "Epoch 278, Loss: 425.99652099609375, y_pred preview: tensor([0.2442])\n",
      "Epoch 279, Loss: 425.4599304199219, y_pred preview: tensor([0.2442])\n",
      "Epoch 280, Loss: 424.9233093261719, y_pred preview: tensor([0.2442])\n",
      "Epoch 281, Loss: 424.38671875, y_pred preview: tensor([0.2442])\n",
      "Epoch 282, Loss: 423.8501281738281, y_pred preview: tensor([0.2442])\n",
      "Epoch 283, Loss: 423.3136291503906, y_pred preview: tensor([0.2442])\n",
      "Epoch 284, Loss: 422.77691650390625, y_pred preview: tensor([0.2442])\n",
      "Epoch 285, Loss: 422.240234375, y_pred preview: tensor([0.2442])\n",
      "Epoch 286, Loss: 421.7037048339844, y_pred preview: tensor([0.2442])\n",
      "Epoch 287, Loss: 421.1670837402344, y_pred preview: tensor([0.2442])\n",
      "Epoch 288, Loss: 420.6304016113281, y_pred preview: tensor([0.2442])\n",
      "Epoch 289, Loss: 420.0938415527344, y_pred preview: tensor([0.2442])\n",
      "Epoch 290, Loss: 419.5572509765625, y_pred preview: tensor([0.2442])\n",
      "Epoch 291, Loss: 419.02069091796875, y_pred preview: tensor([0.2442])\n",
      "Epoch 292, Loss: 418.48406982421875, y_pred preview: tensor([0.2442])\n",
      "Epoch 293, Loss: 417.94744873046875, y_pred preview: tensor([0.2442])\n",
      "Epoch 294, Loss: 417.4107666015625, y_pred preview: tensor([0.2442])\n",
      "Epoch 295, Loss: 416.87420654296875, y_pred preview: tensor([0.2442])\n",
      "Epoch 296, Loss: 416.3376159667969, y_pred preview: tensor([0.2442])\n",
      "Epoch 297, Loss: 415.80096435546875, y_pred preview: tensor([0.2442])\n",
      "Epoch 298, Loss: 415.2642822265625, y_pred preview: tensor([0.2442])\n",
      "Epoch 299, Loss: 414.72784423828125, y_pred preview: tensor([0.2442])\n",
      "Epoch 300, Loss: 414.19122314453125, y_pred preview: tensor([0.2442])\n",
      "Epoch 301, Loss: 413.6545715332031, y_pred preview: tensor([0.2442])\n",
      "Epoch 302, Loss: 413.117919921875, y_pred preview: tensor([0.2442])\n",
      "Epoch 303, Loss: 412.58123779296875, y_pred preview: tensor([0.2442])\n",
      "Epoch 304, Loss: 412.044677734375, y_pred preview: tensor([0.2442])\n",
      "Epoch 305, Loss: 411.508056640625, y_pred preview: tensor([0.2442])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 306, Loss: 410.9715270996094, y_pred preview: tensor([0.2442])\n",
      "Epoch 307, Loss: 410.4350280761719, y_pred preview: tensor([0.2442])\n",
      "Epoch 308, Loss: 409.8983459472656, y_pred preview: tensor([0.2442])\n",
      "Epoch 309, Loss: 409.3617858886719, y_pred preview: tensor([0.2442])\n",
      "Epoch 310, Loss: 408.8251647949219, y_pred preview: tensor([0.2442])\n",
      "Epoch 311, Loss: 408.28851318359375, y_pred preview: tensor([0.2442])\n",
      "Epoch 312, Loss: 407.7519226074219, y_pred preview: tensor([0.2442])\n",
      "Epoch 313, Loss: 407.2152404785156, y_pred preview: tensor([0.2441])\n",
      "Epoch 314, Loss: 406.6786804199219, y_pred preview: tensor([0.2441])\n",
      "Epoch 315, Loss: 406.1420593261719, y_pred preview: tensor([0.2441])\n",
      "Epoch 316, Loss: 405.6054992675781, y_pred preview: tensor([0.2441])\n",
      "Epoch 317, Loss: 405.06890869140625, y_pred preview: tensor([0.2441])\n",
      "Epoch 318, Loss: 404.5322265625, y_pred preview: tensor([0.2441])\n",
      "Epoch 319, Loss: 403.99566650390625, y_pred preview: tensor([0.2441])\n",
      "Epoch 320, Loss: 403.4590148925781, y_pred preview: tensor([0.2441])\n",
      "Epoch 321, Loss: 402.9223937988281, y_pred preview: tensor([0.2441])\n",
      "Epoch 322, Loss: 402.38592529296875, y_pred preview: tensor([0.2441])\n",
      "Epoch 323, Loss: 401.84930419921875, y_pred preview: tensor([0.2441])\n",
      "Epoch 324, Loss: 401.3126525878906, y_pred preview: tensor([0.2441])\n",
      "Epoch 325, Loss: 400.77606201171875, y_pred preview: tensor([0.2441])\n",
      "Epoch 326, Loss: 400.239501953125, y_pred preview: tensor([0.2441])\n",
      "Epoch 327, Loss: 399.7028503417969, y_pred preview: tensor([0.2441])\n",
      "Epoch 328, Loss: 399.166259765625, y_pred preview: tensor([0.2441])\n",
      "Epoch 329, Loss: 398.629638671875, y_pred preview: tensor([0.2441])\n",
      "Epoch 330, Loss: 398.093017578125, y_pred preview: tensor([0.2441])\n",
      "Epoch 331, Loss: 397.55633544921875, y_pred preview: tensor([0.2441])\n",
      "Epoch 332, Loss: 397.0198059082031, y_pred preview: tensor([0.2441])\n",
      "Epoch 333, Loss: 396.48321533203125, y_pred preview: tensor([0.2441])\n",
      "Epoch 334, Loss: 395.9465637207031, y_pred preview: tensor([0.2441])\n",
      "Epoch 335, Loss: 395.4100036621094, y_pred preview: tensor([0.2441])\n",
      "Epoch 336, Loss: 394.8734130859375, y_pred preview: tensor([0.2441])\n",
      "Epoch 337, Loss: 394.3367614746094, y_pred preview: tensor([0.2441])\n",
      "Epoch 338, Loss: 393.8001708984375, y_pred preview: tensor([0.2441])\n",
      "Epoch 339, Loss: 393.2635498046875, y_pred preview: tensor([0.2441])\n",
      "Epoch 340, Loss: 392.7269287109375, y_pred preview: tensor([0.2441])\n",
      "Epoch 341, Loss: 392.1903991699219, y_pred preview: tensor([0.2441])\n",
      "Epoch 342, Loss: 391.6537170410156, y_pred preview: tensor([0.2441])\n",
      "Epoch 343, Loss: 391.1170959472656, y_pred preview: tensor([0.2441])\n",
      "Epoch 344, Loss: 390.58050537109375, y_pred preview: tensor([0.2441])\n",
      "Epoch 345, Loss: 390.0439453125, y_pred preview: tensor([0.2441])\n",
      "Epoch 346, Loss: 389.5073547363281, y_pred preview: tensor([0.2441])\n",
      "Epoch 347, Loss: 388.9707336425781, y_pred preview: tensor([0.2441])\n",
      "Epoch 348, Loss: 388.4341125488281, y_pred preview: tensor([0.2441])\n",
      "Epoch 349, Loss: 387.8975524902344, y_pred preview: tensor([0.2441])\n",
      "Epoch 350, Loss: 387.3608703613281, y_pred preview: tensor([0.2441])\n",
      "Epoch 351, Loss: 386.82421875, y_pred preview: tensor([0.2441])\n",
      "Epoch 352, Loss: 386.2876281738281, y_pred preview: tensor([0.2441])\n",
      "Epoch 353, Loss: 385.7511291503906, y_pred preview: tensor([0.2441])\n",
      "Epoch 354, Loss: 385.2144470214844, y_pred preview: tensor([0.2441])\n",
      "Epoch 355, Loss: 384.6778564453125, y_pred preview: tensor([0.2441])\n",
      "Epoch 356, Loss: 384.1412353515625, y_pred preview: tensor([0.2441])\n",
      "Epoch 357, Loss: 383.6046142578125, y_pred preview: tensor([0.2441])\n",
      "Epoch 358, Loss: 383.0679626464844, y_pred preview: tensor([0.2441])\n",
      "Epoch 359, Loss: 382.5313720703125, y_pred preview: tensor([0.2441])\n",
      "Epoch 360, Loss: 381.9947509765625, y_pred preview: tensor([0.2441])\n",
      "Epoch 361, Loss: 381.4581604003906, y_pred preview: tensor([0.2441])\n",
      "Epoch 362, Loss: 380.921630859375, y_pred preview: tensor([0.2441])\n",
      "Epoch 363, Loss: 380.385009765625, y_pred preview: tensor([0.2441])\n",
      "Epoch 364, Loss: 379.848388671875, y_pred preview: tensor([0.2441])\n",
      "Epoch 365, Loss: 379.3117980957031, y_pred preview: tensor([0.2441])\n",
      "Epoch 366, Loss: 378.775146484375, y_pred preview: tensor([0.2441])\n",
      "Epoch 367, Loss: 378.2385559082031, y_pred preview: tensor([0.2441])\n",
      "Epoch 368, Loss: 377.70196533203125, y_pred preview: tensor([0.2441])\n",
      "Epoch 369, Loss: 377.1654052734375, y_pred preview: tensor([0.2441])\n",
      "Epoch 370, Loss: 376.6287536621094, y_pred preview: tensor([0.2441])\n",
      "Epoch 371, Loss: 376.09210205078125, y_pred preview: tensor([0.2441])\n",
      "Epoch 372, Loss: 375.5555419921875, y_pred preview: tensor([0.2441])\n",
      "Epoch 373, Loss: 375.0189208984375, y_pred preview: tensor([0.2441])\n",
      "Epoch 374, Loss: 374.4823303222656, y_pred preview: tensor([0.2441])\n",
      "Epoch 375, Loss: 373.9457092285156, y_pred preview: tensor([0.2441])\n",
      "Epoch 376, Loss: 373.4091796875, y_pred preview: tensor([0.2441])\n",
      "Epoch 377, Loss: 372.8725280761719, y_pred preview: tensor([0.2441])\n",
      "Epoch 378, Loss: 372.3359375, y_pred preview: tensor([0.2440])\n",
      "Epoch 379, Loss: 371.7993469238281, y_pred preview: tensor([0.2440])\n",
      "Epoch 380, Loss: 371.2626953125, y_pred preview: tensor([0.2440])\n",
      "Epoch 381, Loss: 370.7260437011719, y_pred preview: tensor([0.2440])\n",
      "Epoch 382, Loss: 370.1894836425781, y_pred preview: tensor([0.2440])\n",
      "Epoch 383, Loss: 369.65289306640625, y_pred preview: tensor([0.2440])\n",
      "Epoch 384, Loss: 369.1163330078125, y_pred preview: tensor([0.2440])\n",
      "Epoch 385, Loss: 368.5796203613281, y_pred preview: tensor([0.2440])\n",
      "Epoch 386, Loss: 368.0429992675781, y_pred preview: tensor([0.2440])\n",
      "Epoch 387, Loss: 367.50640869140625, y_pred preview: tensor([0.2440])\n",
      "Epoch 388, Loss: 366.9698181152344, y_pred preview: tensor([0.2440])\n",
      "Epoch 389, Loss: 366.4331970214844, y_pred preview: tensor([0.2440])\n",
      "Epoch 390, Loss: 365.8966369628906, y_pred preview: tensor([0.2440])\n",
      "Epoch 391, Loss: 365.36004638671875, y_pred preview: tensor([0.2440])\n",
      "Epoch 392, Loss: 364.823486328125, y_pred preview: tensor([0.2440])\n",
      "Epoch 393, Loss: 364.28680419921875, y_pred preview: tensor([0.2440])\n",
      "Epoch 394, Loss: 363.75018310546875, y_pred preview: tensor([0.2440])\n",
      "Epoch 395, Loss: 363.213623046875, y_pred preview: tensor([0.2440])\n",
      "Epoch 396, Loss: 362.677001953125, y_pred preview: tensor([0.2440])\n",
      "Epoch 397, Loss: 362.1403503417969, y_pred preview: tensor([0.2440])\n",
      "Epoch 398, Loss: 361.603759765625, y_pred preview: tensor([0.2440])\n",
      "Epoch 399, Loss: 361.06719970703125, y_pred preview: tensor([0.2440])\n",
      "Epoch 400, Loss: 360.53045654296875, y_pred preview: tensor([0.2440])\n",
      "Epoch 401, Loss: 359.993896484375, y_pred preview: tensor([0.2440])\n",
      "Epoch 402, Loss: 359.4571838378906, y_pred preview: tensor([0.2440])\n",
      "Epoch 403, Loss: 358.9206237792969, y_pred preview: tensor([0.2440])\n",
      "Epoch 404, Loss: 358.384033203125, y_pred preview: tensor([0.2440])\n",
      "Epoch 405, Loss: 357.8473815917969, y_pred preview: tensor([0.2440])\n",
      "Epoch 406, Loss: 357.3108215332031, y_pred preview: tensor([0.2440])\n",
      "Epoch 407, Loss: 356.7741394042969, y_pred preview: tensor([0.2440])\n",
      "Epoch 408, Loss: 356.2375793457031, y_pred preview: tensor([0.2440])\n",
      "Epoch 409, Loss: 355.7008972167969, y_pred preview: tensor([0.2440])\n",
      "Epoch 410, Loss: 355.16436767578125, y_pred preview: tensor([0.2440])\n",
      "Epoch 411, Loss: 354.627685546875, y_pred preview: tensor([0.2440])\n",
      "Epoch 412, Loss: 354.0911865234375, y_pred preview: tensor([0.2440])\n",
      "Epoch 413, Loss: 353.5545349121094, y_pred preview: tensor([0.2440])\n",
      "Epoch 414, Loss: 353.0179443359375, y_pred preview: tensor([0.2440])\n",
      "Epoch 415, Loss: 352.4812927246094, y_pred preview: tensor([0.2440])\n",
      "Epoch 416, Loss: 351.9447021484375, y_pred preview: tensor([0.2440])\n",
      "Epoch 417, Loss: 351.4081115722656, y_pred preview: tensor([0.2440])\n",
      "Epoch 418, Loss: 350.8714904785156, y_pred preview: tensor([0.2440])\n",
      "Epoch 419, Loss: 350.3349609375, y_pred preview: tensor([0.2440])\n",
      "Epoch 420, Loss: 349.7983093261719, y_pred preview: tensor([0.2440])\n",
      "Epoch 421, Loss: 349.2616882324219, y_pred preview: tensor([0.2440])\n",
      "Epoch 422, Loss: 348.72503662109375, y_pred preview: tensor([0.2440])\n",
      "Epoch 423, Loss: 348.1883850097656, y_pred preview: tensor([0.2440])\n",
      "Epoch 424, Loss: 347.65179443359375, y_pred preview: tensor([0.2440])\n",
      "Epoch 425, Loss: 347.115234375, y_pred preview: tensor([0.2440])\n",
      "Epoch 426, Loss: 346.5785827636719, y_pred preview: tensor([0.2440])\n",
      "Epoch 427, Loss: 346.0420227050781, y_pred preview: tensor([0.2440])\n",
      "Epoch 428, Loss: 345.50543212890625, y_pred preview: tensor([0.2440])\n",
      "Epoch 429, Loss: 344.9687805175781, y_pred preview: tensor([0.2440])\n",
      "Epoch 430, Loss: 344.43218994140625, y_pred preview: tensor([0.2440])\n",
      "Epoch 431, Loss: 343.8956298828125, y_pred preview: tensor([0.2440])\n",
      "Epoch 432, Loss: 343.3589782714844, y_pred preview: tensor([0.2440])\n",
      "Epoch 433, Loss: 342.8223571777344, y_pred preview: tensor([0.2440])\n",
      "Epoch 434, Loss: 342.2857666015625, y_pred preview: tensor([0.2440])\n",
      "Epoch 435, Loss: 341.7491455078125, y_pred preview: tensor([0.2440])\n",
      "Epoch 436, Loss: 341.2125244140625, y_pred preview: tensor([0.2440])\n",
      "Epoch 437, Loss: 340.6759033203125, y_pred preview: tensor([0.2440])\n",
      "Epoch 438, Loss: 340.13934326171875, y_pred preview: tensor([0.2440])\n",
      "Epoch 439, Loss: 339.6026916503906, y_pred preview: tensor([0.2440])\n",
      "Epoch 440, Loss: 339.06610107421875, y_pred preview: tensor([0.2440])\n",
      "Epoch 441, Loss: 338.52947998046875, y_pred preview: tensor([0.2440])\n",
      "Epoch 442, Loss: 337.992919921875, y_pred preview: tensor([0.2440])\n",
      "Epoch 443, Loss: 337.4563293457031, y_pred preview: tensor([0.2439])\n",
      "Epoch 444, Loss: 336.919677734375, y_pred preview: tensor([0.2439])\n",
      "Epoch 445, Loss: 336.383056640625, y_pred preview: tensor([0.2439])\n",
      "Epoch 446, Loss: 335.846435546875, y_pred preview: tensor([0.2439])\n",
      "Epoch 447, Loss: 335.3099365234375, y_pred preview: tensor([0.2439])\n",
      "Epoch 448, Loss: 334.7732849121094, y_pred preview: tensor([0.2439])\n",
      "Epoch 449, Loss: 334.2366943359375, y_pred preview: tensor([0.2439])\n",
      "Epoch 450, Loss: 333.7000427246094, y_pred preview: tensor([0.2439])\n",
      "Epoch 451, Loss: 333.1634826660156, y_pred preview: tensor([0.2439])\n",
      "Epoch 452, Loss: 332.6268310546875, y_pred preview: tensor([0.2439])\n",
      "Epoch 453, Loss: 332.09027099609375, y_pred preview: tensor([0.2439])\n",
      "Epoch 454, Loss: 331.5535888671875, y_pred preview: tensor([0.2439])\n",
      "Epoch 455, Loss: 331.0169982910156, y_pred preview: tensor([0.2439])\n",
      "Epoch 456, Loss: 330.4803466796875, y_pred preview: tensor([0.2439])\n",
      "Epoch 457, Loss: 329.94378662109375, y_pred preview: tensor([0.2439])\n",
      "Epoch 458, Loss: 329.4071350097656, y_pred preview: tensor([0.2439])\n",
      "Epoch 459, Loss: 328.87054443359375, y_pred preview: tensor([0.2439])\n",
      "Epoch 460, Loss: 328.3338928222656, y_pred preview: tensor([0.2439])\n",
      "Epoch 461, Loss: 327.7973327636719, y_pred preview: tensor([0.2439])\n",
      "Epoch 462, Loss: 327.2607116699219, y_pred preview: tensor([0.2439])\n",
      "Epoch 463, Loss: 326.7240295410156, y_pred preview: tensor([0.2439])\n",
      "Epoch 464, Loss: 326.1874694824219, y_pred preview: tensor([0.2439])\n",
      "Epoch 465, Loss: 325.6509094238281, y_pred preview: tensor([0.2439])\n",
      "Epoch 466, Loss: 325.1142578125, y_pred preview: tensor([0.2439])\n",
      "Epoch 467, Loss: 324.57763671875, y_pred preview: tensor([0.2439])\n",
      "Epoch 468, Loss: 324.04107666015625, y_pred preview: tensor([0.2439])\n",
      "Epoch 469, Loss: 323.5044860839844, y_pred preview: tensor([0.2439])\n",
      "Epoch 470, Loss: 322.9679260253906, y_pred preview: tensor([0.2439])\n",
      "Epoch 471, Loss: 322.4312438964844, y_pred preview: tensor([0.2439])\n",
      "Epoch 472, Loss: 321.8946228027344, y_pred preview: tensor([0.2439])\n",
      "Epoch 473, Loss: 321.3580322265625, y_pred preview: tensor([0.2439])\n",
      "Epoch 474, Loss: 320.82147216796875, y_pred preview: tensor([0.2439])\n",
      "Epoch 475, Loss: 320.2847900390625, y_pred preview: tensor([0.2439])\n",
      "Epoch 476, Loss: 319.74822998046875, y_pred preview: tensor([0.2439])\n",
      "Epoch 477, Loss: 319.21160888671875, y_pred preview: tensor([0.2439])\n",
      "Epoch 478, Loss: 318.6750183105469, y_pred preview: tensor([0.2439])\n",
      "Epoch 479, Loss: 318.138427734375, y_pred preview: tensor([0.2439])\n",
      "Epoch 480, Loss: 317.60174560546875, y_pred preview: tensor([0.2439])\n",
      "Epoch 481, Loss: 317.065185546875, y_pred preview: tensor([0.2439])\n",
      "Epoch 482, Loss: 316.5285949707031, y_pred preview: tensor([0.2439])\n",
      "Epoch 483, Loss: 315.99200439453125, y_pred preview: tensor([0.2439])\n",
      "Epoch 484, Loss: 315.4553527832031, y_pred preview: tensor([0.2439])\n",
      "Epoch 485, Loss: 314.91876220703125, y_pred preview: tensor([0.2439])\n",
      "Epoch 486, Loss: 314.3821716308594, y_pred preview: tensor([0.2439])\n",
      "Epoch 487, Loss: 313.8455810546875, y_pred preview: tensor([0.2439])\n",
      "Epoch 488, Loss: 313.3089599609375, y_pred preview: tensor([0.2439])\n",
      "Epoch 489, Loss: 312.7723083496094, y_pred preview: tensor([0.2439])\n",
      "Epoch 490, Loss: 312.2357177734375, y_pred preview: tensor([0.2439])\n",
      "Epoch 491, Loss: 311.6990966796875, y_pred preview: tensor([0.2439])\n",
      "Epoch 492, Loss: 311.16253662109375, y_pred preview: tensor([0.2439])\n",
      "Epoch 493, Loss: 310.6258850097656, y_pred preview: tensor([0.2439])\n",
      "Epoch 494, Loss: 310.0892639160156, y_pred preview: tensor([0.2439])\n",
      "Epoch 495, Loss: 309.55267333984375, y_pred preview: tensor([0.2439])\n",
      "Epoch 496, Loss: 309.0160827636719, y_pred preview: tensor([0.2439])\n",
      "Epoch 497, Loss: 308.4794616699219, y_pred preview: tensor([0.2439])\n",
      "Epoch 498, Loss: 307.9428405761719, y_pred preview: tensor([0.2439])\n",
      "Epoch 499, Loss: 307.40625, y_pred preview: tensor([0.2439])\n",
      "Train Loss: 306.8696594238281\n",
      "Test Losss: 346.681396484375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(306.8697), tensor(346.6814))"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train linear regression\n",
    "assessor_config =  config['assessor']\n",
    "assessor_config['linear_regression']['epochs'] = 500\n",
    "assessor = HomeAssessor(assessor_config)\n",
    "\n",
    "calculate_train_val_loss(assessor, \n",
    "                         train_test_dataset['train_x'], \n",
    "                         train_test_dataset['train_y'],\n",
    "                         train_test_dataset['test_x'],\n",
    "                         train_test_dataset['test_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train nn module\n",
    "assessor_config =  config['assessor']\n",
    "assessor_config['simple_nn']['epochs'] = 10\n",
    "assessor_config['model'] = 'simple_nn'\n",
    "assessor = HomeAssessor(assessor_config)\n",
    "\n",
    "calculate_train_val_loss(assessor, train_x_split, train_y_split, test_x_split, test_y_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
