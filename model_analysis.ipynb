{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######\n",
    "# load data to pandas\n",
    "# train\n",
    "# tune parameters on holdout set\n",
    "# test\n",
    "# kfolds cross validation\n",
    "#######\n",
    "# comparisons:\n",
    "# linear regression\n",
    "# decision trees (random forest via scikit learn)\n",
    "# ff neural network (lin, relu, lin) higher order polyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Imports\n",
    "import pandas as pd\n",
    "from core_insure.assessor.home_assessor import HomeAssessor\n",
    "from ruamel.yaml import YAML\n",
    "import numpy as np\n",
    "import math\n",
    "from torch import nn\n",
    "\n",
    "LABEL_KEY = 'claimAmount'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lisajiang/magikarp/core_insure/venv/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (31,32,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Load data to pandas\n",
    "# This dataset was downloaded from: \n",
    "# https://www.fema.gov/openfema-dataset-individual-assistance-housing-registrants-large-disasters-v1\n",
    "file = open('core_insure/data/IndividualAssistanceHousingRegistrantsLargeDisasters.csv', 'r')\n",
    "pd_data = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['censusBlockId', 'censusYear', 'claimAmount', 'damagedZipCode', 'destroyed', 'disasterNumber', 'floodDamage', 'floodInsurance', 'foundationDamage', 'foundationDamageAmount', 'grossIncome', 'habitabilityRepairsRequired', 'homeOwnersInsurance', 'householdComposition', 'inspected', 'personalPropertyEligible', 'ppfvl', 'primaryResidence', 'rentalAssistanceAmount', 'rentalAssistanceEligible', 'rentalResourceZipCode', 'repairAmount', 'repairAssistanceEligible', 'replacementAmount', 'replacementAssistanceEligible', 'roofDamage', 'roofDamageAmount', 'rpfvl', 'sbaEligible', 'specialNeeds', 'tsaCheckedIn', 'tsaEligible', 'waterLevel']\n"
     ]
    }
   ],
   "source": [
    "# Columns available\n",
    "all_columns = list(pd_data.columns.values)\n",
    "\n",
    "# calculate label: claimAmount based on repairs and replacements\n",
    "pd_data = pd_data.fillna(0)\n",
    "pd_data[LABEL_KEY] = pd_data['repairAmount'] + pd_data['replacementAmount']\n",
    "\n",
    "# For now, filter on just numerical data\n",
    "# Later, can convert string columns (embedding, bins, num categories)\n",
    "only_numerical_data = pd_data._get_numeric_data()\n",
    "sorted_numerical_df = pd_data.reindex(sorted(only_numerical_data.columns), axis=1)\n",
    "numeric_columns = sorted(sorted_numerical_df.columns.values)\n",
    "print(list(numeric_columns))\n",
    "\n",
    "# remove all data where repairs were not made\n",
    "sorted_numerical_df = sorted_numerical_df.replace(0, np.nan)\n",
    "sorted_numerical_df = sorted_numerical_df[sorted_numerical_df[LABEL_KEY].notnull()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     repairAmount  claimAmount\n",
      "52        2578.09      2578.09\n",
      "57       15397.22     15397.22\n",
      "58        2164.50      2164.50\n",
      "70        4189.79      4189.79\n",
      "82         499.50       499.50\n",
      "94        6048.26      6048.26\n",
      "128        139.64       139.64\n",
      "152       2269.65      2269.65\n",
      "158       1953.13      1953.13\n",
      "165        269.81       269.81\n"
     ]
    }
   ],
   "source": [
    "# columns = [\n",
    "#     'damagedZipCode',\n",
    "#     'disasterNumber',\n",
    "#     'foundationDamageAmount', \n",
    "#     'grossIncome', \n",
    "#     'householdComposition',\n",
    "#     'roofDamageAmount',\n",
    "#     'waterLevel',\n",
    "#     LABEL_KEY\n",
    "# ]\n",
    "columns = [\n",
    "    'repairAmount',\n",
    "    LABEL_KEY\n",
    "]\n",
    "final_sorted_df = sorted_numerical_df[sorted_numerical_df['repairAmount'].notnull()] \n",
    "final_sorted_df = pd.DataFrame(sorted_numerical_df, columns=columns)\n",
    "# final_sorted_df = final_sorted_df.replace(np.nan,1)\n",
    "final_sorted_df = final_sorted_df.replace(0,1)\n",
    "print(final_sorted_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing and training methods\n",
    "def value_of_interest(value):\n",
    "    if pd.isna(value):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def get_row_xy(row):\n",
    "    y_label = row[LABEL_KEY] if value_of_interest(row[LABEL_KEY]) else 0\n",
    "    row = row.drop([LABEL_KEY])\n",
    "    rowiter = row.iteritems()\n",
    "    x_array = [item[1] if value_of_interest(item[1]) else 0 for item in rowiter]\n",
    "    return x_array, y_label\n",
    "\n",
    "def get_all_xy(df):\n",
    "    all_x = []\n",
    "    all_y = []\n",
    "    for row in df.iterrows():\n",
    "        row_contents = row[1]\n",
    "        x, y = get_row_xy(row_contents)\n",
    "        all_x.append(x)\n",
    "        all_y.append([y])\n",
    "    return all_x, all_y\n",
    "\n",
    "def calculate_train_val_loss(curr_assessor, train_x, train_y, test_x, test_y):\n",
    "    # exploding gradients?\n",
    "    train_output = curr_assessor.train(train_x, train_y)\n",
    "\n",
    "    # Train loss \n",
    "    model = curr_assessor.model\n",
    "    train_pred_y = model.eval(train_x)\n",
    "    loss = model.loss\n",
    "    train_loss = loss(model._torch_var(train_pred_y), model._torch_var(train_y))\n",
    "    print(f'Train Loss: {train_loss}')\n",
    "    \n",
    "    # Test linear regression\n",
    "    test_y_pred = model.eval(test_x)\n",
    "    test_loss = loss(model._torch_var(test_y_pred), model._torch_var(test_y))\n",
    "    print(f'Test Losss: {test_loss}')\n",
    "    \n",
    "    return train_loss, test_loss\n",
    "\n",
    "# def train_with_config(linreg_config, df_data):\n",
    "#     epochs = linreg_config.get('epochs')\n",
    "#     epoch_loss = 0\n",
    "#     for epoch in range(epochs):\n",
    "#         for row in df_data.iterrows():\n",
    "#             row_contents = row[1]\n",
    "#             x, y = get_row_xy(row_contents)\n",
    "#             \n",
    "#             y_pred = self.model(self._torch_var(x))\n",
    "#             loss = self.loss(y_pred, self._torch_var(y))\n",
    "#             epoch_loss = loss.data[0]\n",
    "#     \n",
    "#             self.optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             self.optimizer.step()\n",
    "#         print(f'Epoch {epoch} loss: {epoch_loss}')\n",
    "\n",
    "# train_with_config(linreg_config, sorted_numerical_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total test set: 277242\n",
      "Training set: 221793, Testing set: 55449\n",
      "Get training set\n",
      "Get testing set\n"
     ]
    }
   ],
   "source": [
    "# 80-20 Split\n",
    "total_rows = final_sorted_df.shape[0]\n",
    "print(f'Total test set: {total_rows}')\n",
    "train_size = math.floor(total_rows*.80)\n",
    "test_size = total_rows - train_size\n",
    "print(f'Training set: {train_size}, Testing set: {test_size}')\n",
    "\n",
    "train_x_split, train_y_split = get_all_xy(final_sorted_df.head(100))\n",
    "print(\"Get training set\")\n",
    "test_x_split, test_y_split = get_all_xy(final_sorted_df.tail(10))\n",
    "print(\"Get testing set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ordereddict([('base', ordereddict([('filepath', '.')])), ('assessor', ordereddict([('model', 'linear_regression'), ('linear_regression', ordereddict([('output_size', 1), ('lr', 1e-05), ('momentum', 0), ('epochs', 500)])), ('simple_nn', ordereddict([('output_size', 1), ('lr', 0.001), ('epochs', 500), ('hidden_size', 50)])), ('filepath', '.')]))])\n"
     ]
    }
   ],
   "source": [
    "# Get config\n",
    "default_config_file = open('core_insure/config.yaml', 'r')\n",
    "yaml = YAML()\n",
    "config = yaml.load(default_config_file)\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lisajiang/magikarp/core_insure/assessor/linear_regression.py:44: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  print(f'Epoch {epoch}, Loss: {loss}, y_pred preview: {y_pred.data[0]}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 4133.81103515625, y_pred preview: tensor([161.8046])\n",
      "Epoch 1, Loss: 4016.253662109375, y_pred preview: tensor([250.1991])\n",
      "Epoch 2, Loss: 3898.694580078125, y_pred preview: tensor([338.5935])\n",
      "Epoch 3, Loss: 3781.1357421875, y_pred preview: tensor([426.9880])\n",
      "Epoch 4, Loss: 3663.578369140625, y_pred preview: tensor([515.3824])\n",
      "Epoch 5, Loss: 3546.0185546875, y_pred preview: tensor([603.7769])\n",
      "Epoch 6, Loss: 3428.460205078125, y_pred preview: tensor([692.1714])\n",
      "Epoch 7, Loss: 3310.901611328125, y_pred preview: tensor([780.5659])\n",
      "Epoch 8, Loss: 3193.34375, y_pred preview: tensor([868.9603])\n",
      "Epoch 9, Loss: 3075.785400390625, y_pred preview: tensor([957.3548])\n",
      "Epoch 10, Loss: 2958.226806640625, y_pred preview: tensor([1045.7493])\n",
      "Epoch 11, Loss: 2840.668212890625, y_pred preview: tensor([1134.1438])\n",
      "Epoch 12, Loss: 2723.1103515625, y_pred preview: tensor([1222.5382])\n",
      "Epoch 13, Loss: 2605.551025390625, y_pred preview: tensor([1310.9326])\n",
      "Epoch 14, Loss: 2487.992431640625, y_pred preview: tensor([1399.3271])\n",
      "Epoch 15, Loss: 2370.433837890625, y_pred preview: tensor([1487.7216])\n",
      "Epoch 16, Loss: 2252.875732421875, y_pred preview: tensor([1576.1160])\n",
      "Epoch 17, Loss: 2135.317626953125, y_pred preview: tensor([1664.5105])\n",
      "Epoch 18, Loss: 2017.759521484375, y_pred preview: tensor([1752.9049])\n",
      "Epoch 19, Loss: 1900.200439453125, y_pred preview: tensor([1841.2993])\n",
      "Epoch 20, Loss: 1782.6417236328125, y_pred preview: tensor([1929.6938])\n",
      "Epoch 21, Loss: 1665.08349609375, y_pred preview: tensor([2018.0883])\n",
      "Epoch 22, Loss: 1547.5255126953125, y_pred preview: tensor([2106.4827])\n",
      "Epoch 23, Loss: 1429.9659423828125, y_pred preview: tensor([2194.8772])\n",
      "Epoch 24, Loss: 1312.408447265625, y_pred preview: tensor([2283.2717])\n",
      "Epoch 25, Loss: 1194.8494873046875, y_pred preview: tensor([2371.6660])\n",
      "Epoch 26, Loss: 1077.291259765625, y_pred preview: tensor([2460.0605])\n",
      "Epoch 27, Loss: 959.7413940429688, y_pred preview: tensor([2548.4551])\n",
      "Epoch 28, Loss: 997.7100219726562, y_pred preview: tensor([2636.8179])\n",
      "Epoch 29, Loss: 959.7832641601562, y_pred preview: tensor([2548.4233])\n",
      "Epoch 30, Loss: 997.667724609375, y_pred preview: tensor([2636.7861])\n",
      "Epoch 31, Loss: 959.8255615234375, y_pred preview: tensor([2548.3916])\n",
      "Epoch 32, Loss: 997.6260986328125, y_pred preview: tensor([2636.7544])\n",
      "Epoch 33, Loss: 959.8677978515625, y_pred preview: tensor([2548.3601])\n",
      "Epoch 34, Loss: 997.583984375, y_pred preview: tensor([2636.7229])\n",
      "Epoch 35, Loss: 959.9097900390625, y_pred preview: tensor([2548.3284])\n",
      "Epoch 36, Loss: 997.5421142578125, y_pred preview: tensor([2636.6917])\n",
      "Epoch 37, Loss: 959.951171875, y_pred preview: tensor([2548.2971])\n",
      "Epoch 38, Loss: 997.5003662109375, y_pred preview: tensor([2636.6604])\n",
      "Epoch 39, Loss: 959.9932250976562, y_pred preview: tensor([2548.2656])\n",
      "Epoch 40, Loss: 997.4586791992188, y_pred preview: tensor([2636.6289])\n",
      "Epoch 41, Loss: 960.0348510742188, y_pred preview: tensor([2548.2344])\n",
      "Epoch 42, Loss: 997.4171752929688, y_pred preview: tensor([2636.5977])\n",
      "Epoch 43, Loss: 960.0764770507812, y_pred preview: tensor([2548.2029])\n",
      "Epoch 44, Loss: 997.3755493164062, y_pred preview: tensor([2636.5664])\n",
      "Epoch 45, Loss: 960.1182861328125, y_pred preview: tensor([2548.1716])\n",
      "Epoch 46, Loss: 997.3340454101562, y_pred preview: tensor([2636.5354])\n",
      "Epoch 47, Loss: 960.1593017578125, y_pred preview: tensor([2548.1406])\n",
      "Epoch 48, Loss: 997.292724609375, y_pred preview: tensor([2636.5042])\n",
      "Epoch 49, Loss: 960.20068359375, y_pred preview: tensor([2548.1096])\n",
      "Epoch 50, Loss: 997.2513427734375, y_pred preview: tensor([2636.4731])\n",
      "Epoch 51, Loss: 960.241943359375, y_pred preview: tensor([2548.0786])\n",
      "Epoch 52, Loss: 997.210205078125, y_pred preview: tensor([2636.4421])\n",
      "Epoch 53, Loss: 960.283447265625, y_pred preview: tensor([2548.0474])\n",
      "Epoch 54, Loss: 997.1693115234375, y_pred preview: tensor([2636.4114])\n",
      "Epoch 55, Loss: 960.32421875, y_pred preview: tensor([2548.0168])\n",
      "Epoch 56, Loss: 997.1282958984375, y_pred preview: tensor([2636.3806])\n",
      "Epoch 57, Loss: 960.3651733398438, y_pred preview: tensor([2547.9861])\n",
      "Epoch 58, Loss: 997.08740234375, y_pred preview: tensor([2636.3499])\n",
      "Epoch 59, Loss: 960.4056396484375, y_pred preview: tensor([2547.9553])\n",
      "Epoch 60, Loss: 997.0468139648438, y_pred preview: tensor([2636.3193])\n",
      "Epoch 61, Loss: 960.4466552734375, y_pred preview: tensor([2547.9246])\n",
      "Epoch 62, Loss: 997.006591796875, y_pred preview: tensor([2636.2888])\n",
      "Epoch 63, Loss: 960.4871826171875, y_pred preview: tensor([2547.8940])\n",
      "Epoch 64, Loss: 996.96630859375, y_pred preview: tensor([2636.2583])\n",
      "Epoch 65, Loss: 960.5277099609375, y_pred preview: tensor([2547.8638])\n",
      "Epoch 66, Loss: 996.92529296875, y_pred preview: tensor([2636.2280])\n",
      "Epoch 67, Loss: 960.5680541992188, y_pred preview: tensor([2547.8333])\n",
      "Epoch 68, Loss: 996.885009765625, y_pred preview: tensor([2636.1975])\n",
      "Epoch 69, Loss: 960.6083374023438, y_pred preview: tensor([2547.8027])\n",
      "Epoch 70, Loss: 996.8443603515625, y_pred preview: tensor([2636.1670])\n",
      "Epoch 71, Loss: 960.64892578125, y_pred preview: tensor([2547.7725])\n",
      "Epoch 72, Loss: 996.8043212890625, y_pred preview: tensor([2636.1370])\n",
      "Epoch 73, Loss: 960.6890869140625, y_pred preview: tensor([2547.7422])\n",
      "Epoch 74, Loss: 996.7642211914062, y_pred preview: tensor([2636.1069])\n",
      "Epoch 75, Loss: 960.7288208007812, y_pred preview: tensor([2547.7122])\n",
      "Epoch 76, Loss: 996.7242431640625, y_pred preview: tensor([2636.0767])\n",
      "Epoch 77, Loss: 960.76904296875, y_pred preview: tensor([2547.6821])\n",
      "Epoch 78, Loss: 996.6843872070312, y_pred preview: tensor([2636.0466])\n",
      "Epoch 79, Loss: 960.8092041015625, y_pred preview: tensor([2547.6519])\n",
      "Epoch 80, Loss: 996.64453125, y_pred preview: tensor([2636.0168])\n",
      "Epoch 81, Loss: 960.8490600585938, y_pred preview: tensor([2547.6221])\n",
      "Epoch 82, Loss: 996.605224609375, y_pred preview: tensor([2635.9871])\n",
      "Epoch 83, Loss: 960.8880615234375, y_pred preview: tensor([2547.5925])\n",
      "Epoch 84, Loss: 996.5653686523438, y_pred preview: tensor([2635.9573])\n",
      "Epoch 85, Loss: 960.9277954101562, y_pred preview: tensor([2547.5627])\n",
      "Epoch 86, Loss: 996.5256958007812, y_pred preview: tensor([2635.9275])\n",
      "Epoch 87, Loss: 960.9673461914062, y_pred preview: tensor([2547.5330])\n",
      "Epoch 88, Loss: 996.486328125, y_pred preview: tensor([2635.8979])\n",
      "Epoch 89, Loss: 961.0069580078125, y_pred preview: tensor([2547.5034])\n",
      "Epoch 90, Loss: 996.4468994140625, y_pred preview: tensor([2635.8684])\n",
      "Epoch 91, Loss: 961.0457153320312, y_pred preview: tensor([2547.4739])\n",
      "Epoch 92, Loss: 996.4078979492188, y_pred preview: tensor([2635.8389])\n",
      "Epoch 93, Loss: 961.0851440429688, y_pred preview: tensor([2547.4443])\n",
      "Epoch 94, Loss: 996.3685913085938, y_pred preview: tensor([2635.8093])\n",
      "Epoch 95, Loss: 961.1243896484375, y_pred preview: tensor([2547.4148])\n",
      "Epoch 96, Loss: 996.3295288085938, y_pred preview: tensor([2635.7798])\n",
      "Epoch 97, Loss: 961.163818359375, y_pred preview: tensor([2547.3855])\n",
      "Epoch 98, Loss: 996.2904663085938, y_pred preview: tensor([2635.7507])\n",
      "Epoch 99, Loss: 961.2027587890625, y_pred preview: tensor([2547.3562])\n",
      "Epoch 100, Loss: 996.251708984375, y_pred preview: tensor([2635.7214])\n",
      "Epoch 101, Loss: 961.2413940429688, y_pred preview: tensor([2547.3269])\n",
      "Epoch 102, Loss: 996.213134765625, y_pred preview: tensor([2635.6924])\n",
      "Epoch 103, Loss: 961.2801513671875, y_pred preview: tensor([2547.2979])\n",
      "Epoch 104, Loss: 996.1737670898438, y_pred preview: tensor([2635.6631])\n",
      "Epoch 105, Loss: 961.3191528320312, y_pred preview: tensor([2547.2686])\n",
      "Epoch 106, Loss: 996.13525390625, y_pred preview: tensor([2635.6338])\n",
      "Epoch 107, Loss: 961.357666015625, y_pred preview: tensor([2547.2395])\n",
      "Epoch 108, Loss: 996.0966186523438, y_pred preview: tensor([2635.6050])\n",
      "Epoch 109, Loss: 961.3964233398438, y_pred preview: tensor([2547.2104])\n",
      "Epoch 110, Loss: 996.0582885742188, y_pred preview: tensor([2635.5762])\n",
      "Epoch 111, Loss: 961.4349975585938, y_pred preview: tensor([2547.1816])\n",
      "Epoch 112, Loss: 996.02001953125, y_pred preview: tensor([2635.5471])\n",
      "Epoch 113, Loss: 961.47314453125, y_pred preview: tensor([2547.1528])\n",
      "Epoch 114, Loss: 995.981689453125, y_pred preview: tensor([2635.5183])\n",
      "Epoch 115, Loss: 961.5114135742188, y_pred preview: tensor([2547.1238])\n",
      "Epoch 116, Loss: 995.94384765625, y_pred preview: tensor([2635.4897])\n",
      "Epoch 117, Loss: 961.5498657226562, y_pred preview: tensor([2547.0952])\n",
      "Epoch 118, Loss: 995.9056396484375, y_pred preview: tensor([2635.4612])\n",
      "Epoch 119, Loss: 961.5875244140625, y_pred preview: tensor([2547.0667])\n",
      "Epoch 120, Loss: 995.8677978515625, y_pred preview: tensor([2635.4326])\n",
      "Epoch 121, Loss: 961.6255493164062, y_pred preview: tensor([2547.0381])\n",
      "Epoch 122, Loss: 995.82958984375, y_pred preview: tensor([2635.4041])\n",
      "Epoch 123, Loss: 961.663330078125, y_pred preview: tensor([2547.0095])\n",
      "Epoch 124, Loss: 995.79150390625, y_pred preview: tensor([2635.3755])\n",
      "Epoch 125, Loss: 961.7017211914062, y_pred preview: tensor([2546.9810])\n",
      "Epoch 126, Loss: 995.7537231445312, y_pred preview: tensor([2635.3472])\n",
      "Epoch 127, Loss: 961.7391967773438, y_pred preview: tensor([2546.9526])\n",
      "Epoch 128, Loss: 995.71630859375, y_pred preview: tensor([2635.3188])\n",
      "Epoch 129, Loss: 961.7764892578125, y_pred preview: tensor([2546.9243])\n",
      "Epoch 130, Loss: 995.6790771484375, y_pred preview: tensor([2635.2905])\n",
      "Epoch 131, Loss: 961.8143920898438, y_pred preview: tensor([2546.8962])\n",
      "Epoch 132, Loss: 995.640869140625, y_pred preview: tensor([2635.2622])\n",
      "Epoch 133, Loss: 961.8517456054688, y_pred preview: tensor([2546.8679])\n",
      "Epoch 134, Loss: 995.6040649414062, y_pred preview: tensor([2635.2344])\n",
      "Epoch 135, Loss: 961.8890380859375, y_pred preview: tensor([2546.8398])\n",
      "Epoch 136, Loss: 995.56689453125, y_pred preview: tensor([2635.2063])\n",
      "Epoch 137, Loss: 961.9263916015625, y_pred preview: tensor([2546.8120])\n",
      "Epoch 138, Loss: 995.5296630859375, y_pred preview: tensor([2635.1785])\n",
      "Epoch 139, Loss: 961.9636840820312, y_pred preview: tensor([2546.7839])\n",
      "Epoch 140, Loss: 995.4922485351562, y_pred preview: tensor([2635.1504])\n",
      "Epoch 141, Loss: 962.0006103515625, y_pred preview: tensor([2546.7561])\n",
      "Epoch 142, Loss: 995.4548950195312, y_pred preview: tensor([2635.1226])\n",
      "Epoch 143, Loss: 962.0379638671875, y_pred preview: tensor([2546.7280])\n",
      "Epoch 144, Loss: 995.4185180664062, y_pred preview: tensor([2635.0947])\n",
      "Epoch 145, Loss: 962.074951171875, y_pred preview: tensor([2546.7004])\n",
      "Epoch 146, Loss: 995.3817138671875, y_pred preview: tensor([2635.0671])\n",
      "Epoch 147, Loss: 962.1111450195312, y_pred preview: tensor([2546.6726])\n",
      "Epoch 148, Loss: 995.3448486328125, y_pred preview: tensor([2635.0396])\n",
      "Epoch 149, Loss: 962.14794921875, y_pred preview: tensor([2546.6450])\n",
      "Epoch 150, Loss: 995.3080444335938, y_pred preview: tensor([2635.0117])\n",
      "Epoch 151, Loss: 962.1847534179688, y_pred preview: tensor([2546.6174])\n",
      "Epoch 152, Loss: 995.2711181640625, y_pred preview: tensor([2634.9841])\n",
      "Epoch 153, Loss: 962.2216186523438, y_pred preview: tensor([2546.5898])\n",
      "Epoch 154, Loss: 995.23486328125, y_pred preview: tensor([2634.9568])\n",
      "Epoch 155, Loss: 962.258056640625, y_pred preview: tensor([2546.5623])\n",
      "Epoch 156, Loss: 995.1983642578125, y_pred preview: tensor([2634.9294])\n",
      "Epoch 157, Loss: 962.29443359375, y_pred preview: tensor([2546.5349])\n",
      "Epoch 158, Loss: 995.1618041992188, y_pred preview: tensor([2634.9021])\n",
      "Epoch 159, Loss: 962.330810546875, y_pred preview: tensor([2546.5076])\n",
      "Epoch 160, Loss: 995.1260986328125, y_pred preview: tensor([2634.8748])\n",
      "Epoch 161, Loss: 962.3672485351562, y_pred preview: tensor([2546.4802])\n",
      "Epoch 162, Loss: 995.0895385742188, y_pred preview: tensor([2634.8474])\n",
      "Epoch 163, Loss: 962.4032592773438, y_pred preview: tensor([2546.4529])\n",
      "Epoch 164, Loss: 995.0531005859375, y_pred preview: tensor([2634.8203])\n",
      "Epoch 165, Loss: 962.4392700195312, y_pred preview: tensor([2546.4260])\n",
      "Epoch 166, Loss: 995.0172729492188, y_pred preview: tensor([2634.7932])\n",
      "Epoch 167, Loss: 962.4754638671875, y_pred preview: tensor([2546.3989])\n",
      "Epoch 168, Loss: 994.9815673828125, y_pred preview: tensor([2634.7664])\n",
      "Epoch 169, Loss: 962.51123046875, y_pred preview: tensor([2546.3718])\n",
      "Epoch 170, Loss: 994.945556640625, y_pred preview: tensor([2634.7393])\n",
      "Epoch 171, Loss: 962.5472412109375, y_pred preview: tensor([2546.3447])\n",
      "Epoch 172, Loss: 994.9095458984375, y_pred preview: tensor([2634.7122])\n",
      "Epoch 173, Loss: 962.5833740234375, y_pred preview: tensor([2546.3176])\n",
      "Epoch 174, Loss: 994.8743896484375, y_pred preview: tensor([2634.6855])\n",
      "Epoch 175, Loss: 962.61865234375, y_pred preview: tensor([2546.2910])\n",
      "Epoch 176, Loss: 994.8385009765625, y_pred preview: tensor([2634.6587])\n",
      "Epoch 177, Loss: 962.654052734375, y_pred preview: tensor([2546.2642])\n",
      "Epoch 178, Loss: 994.8027954101562, y_pred preview: tensor([2634.6321])\n",
      "Epoch 179, Loss: 962.6897583007812, y_pred preview: tensor([2546.2375])\n",
      "Epoch 180, Loss: 994.7669677734375, y_pred preview: tensor([2634.6052])\n",
      "Epoch 181, Loss: 962.725341796875, y_pred preview: tensor([2546.2107])\n",
      "Epoch 182, Loss: 994.7318115234375, y_pred preview: tensor([2634.5786])\n",
      "Epoch 183, Loss: 962.7609252929688, y_pred preview: tensor([2546.1841])\n",
      "Epoch 184, Loss: 994.6964721679688, y_pred preview: tensor([2634.5520])\n",
      "Epoch 185, Loss: 962.7960815429688, y_pred preview: tensor([2546.1577])\n",
      "Epoch 186, Loss: 994.6614990234375, y_pred preview: tensor([2634.5256])\n",
      "Epoch 187, Loss: 962.8312377929688, y_pred preview: tensor([2546.1311])\n",
      "Epoch 188, Loss: 994.6263427734375, y_pred preview: tensor([2634.4993])\n",
      "Epoch 189, Loss: 962.8662719726562, y_pred preview: tensor([2546.1047])\n",
      "Epoch 190, Loss: 994.5912475585938, y_pred preview: tensor([2634.4727])\n",
      "Epoch 191, Loss: 962.9014892578125, y_pred preview: tensor([2546.0784])\n",
      "Epoch 192, Loss: 994.5560302734375, y_pred preview: tensor([2634.4463])\n",
      "Epoch 193, Loss: 962.9366455078125, y_pred preview: tensor([2546.0520])\n",
      "Epoch 194, Loss: 994.521240234375, y_pred preview: tensor([2634.4202])\n",
      "Epoch 195, Loss: 962.9714965820312, y_pred preview: tensor([2546.0259])\n",
      "Epoch 196, Loss: 994.4863891601562, y_pred preview: tensor([2634.3940])\n",
      "Epoch 197, Loss: 963.0061645507812, y_pred preview: tensor([2545.9998])\n",
      "Epoch 198, Loss: 994.45166015625, y_pred preview: tensor([2634.3679])\n",
      "Epoch 199, Loss: 963.0408325195312, y_pred preview: tensor([2545.9736])\n",
      "Epoch 200, Loss: 994.4176025390625, y_pred preview: tensor([2634.3418])\n",
      "Epoch 201, Loss: 963.0758666992188, y_pred preview: tensor([2545.9475])\n",
      "Epoch 202, Loss: 994.382080078125, y_pred preview: tensor([2634.3157])\n",
      "Epoch 203, Loss: 963.1101684570312, y_pred preview: tensor([2545.9214])\n",
      "Epoch 204, Loss: 994.3478393554688, y_pred preview: tensor([2634.2898])\n",
      "Epoch 205, Loss: 963.144775390625, y_pred preview: tensor([2545.8955])\n",
      "Epoch 206, Loss: 994.313720703125, y_pred preview: tensor([2634.2642])\n",
      "Epoch 207, Loss: 963.1788330078125, y_pred preview: tensor([2545.8696])\n",
      "Epoch 208, Loss: 994.2792358398438, y_pred preview: tensor([2634.2383])\n",
      "Epoch 209, Loss: 963.2127075195312, y_pred preview: tensor([2545.8438])\n",
      "Epoch 210, Loss: 994.2449340820312, y_pred preview: tensor([2634.2124])\n",
      "Epoch 211, Loss: 963.247802734375, y_pred preview: tensor([2545.8181])\n",
      "Epoch 212, Loss: 994.2106323242188, y_pred preview: tensor([2634.1868])\n",
      "Epoch 213, Loss: 963.2821655273438, y_pred preview: tensor([2545.7922])\n",
      "Epoch 214, Loss: 994.1769409179688, y_pred preview: tensor([2634.1611])\n",
      "Epoch 215, Loss: 963.3156127929688, y_pred preview: tensor([2545.7666])\n",
      "Epoch 216, Loss: 994.142578125, y_pred preview: tensor([2634.1357])\n",
      "Epoch 217, Loss: 963.349609375, y_pred preview: tensor([2545.7412])\n",
      "Epoch 218, Loss: 994.10888671875, y_pred preview: tensor([2634.1101])\n",
      "Epoch 219, Loss: 963.3839721679688, y_pred preview: tensor([2545.7156])\n",
      "Epoch 220, Loss: 994.074951171875, y_pred preview: tensor([2634.0847])\n",
      "Epoch 221, Loss: 963.41748046875, y_pred preview: tensor([2545.6902])\n",
      "Epoch 222, Loss: 994.0413208007812, y_pred preview: tensor([2634.0591])\n",
      "Epoch 223, Loss: 963.4517211914062, y_pred preview: tensor([2545.6646])\n",
      "Epoch 224, Loss: 994.0074462890625, y_pred preview: tensor([2634.0339])\n",
      "Epoch 225, Loss: 963.4849853515625, y_pred preview: tensor([2545.6394])\n",
      "Epoch 226, Loss: 993.9742431640625, y_pred preview: tensor([2634.0088])\n",
      "Epoch 227, Loss: 963.5184936523438, y_pred preview: tensor([2545.6143])\n",
      "Epoch 228, Loss: 993.9403686523438, y_pred preview: tensor([2633.9834])\n",
      "Epoch 229, Loss: 963.55224609375, y_pred preview: tensor([2545.5891])\n",
      "Epoch 230, Loss: 993.9071655273438, y_pred preview: tensor([2633.9583])\n",
      "Epoch 231, Loss: 963.58544921875, y_pred preview: tensor([2545.5640])\n",
      "Epoch 232, Loss: 993.8733520507812, y_pred preview: tensor([2633.9331])\n",
      "Epoch 233, Loss: 963.6193237304688, y_pred preview: tensor([2545.5386])\n",
      "Epoch 234, Loss: 993.8396606445312, y_pred preview: tensor([2633.9080])\n",
      "Epoch 235, Loss: 963.65283203125, y_pred preview: tensor([2545.5134])\n",
      "Epoch 236, Loss: 993.806884765625, y_pred preview: tensor([2633.8831])\n",
      "Epoch 237, Loss: 963.685546875, y_pred preview: tensor([2545.4885])\n",
      "Epoch 238, Loss: 993.77392578125, y_pred preview: tensor([2633.8582])\n",
      "Epoch 239, Loss: 963.7185668945312, y_pred preview: tensor([2545.4636])\n",
      "Epoch 240, Loss: 993.740234375, y_pred preview: tensor([2633.8333])\n",
      "Epoch 241, Loss: 963.751708984375, y_pred preview: tensor([2545.4387])\n",
      "Epoch 242, Loss: 993.7072143554688, y_pred preview: tensor([2633.8083])\n",
      "Epoch 243, Loss: 963.7849731445312, y_pred preview: tensor([2545.4138])\n",
      "Epoch 244, Loss: 993.6746215820312, y_pred preview: tensor([2633.7834])\n",
      "Epoch 245, Loss: 963.8184204101562, y_pred preview: tensor([2545.3889])\n",
      "Epoch 246, Loss: 993.6414184570312, y_pred preview: tensor([2633.7588])\n",
      "Epoch 247, Loss: 963.8505249023438, y_pred preview: tensor([2545.3645])\n",
      "Epoch 248, Loss: 993.6087646484375, y_pred preview: tensor([2633.7344])\n",
      "Epoch 249, Loss: 963.8837280273438, y_pred preview: tensor([2545.3398])\n",
      "Epoch 250, Loss: 993.576171875, y_pred preview: tensor([2633.7097])\n",
      "Epoch 251, Loss: 963.9160766601562, y_pred preview: tensor([2545.3152])\n",
      "Epoch 252, Loss: 993.543701171875, y_pred preview: tensor([2633.6851])\n",
      "Epoch 253, Loss: 963.948974609375, y_pred preview: tensor([2545.2905])\n",
      "Epoch 254, Loss: 993.5111083984375, y_pred preview: tensor([2633.6604])\n",
      "Epoch 255, Loss: 963.981689453125, y_pred preview: tensor([2545.2661])\n",
      "Epoch 256, Loss: 993.478759765625, y_pred preview: tensor([2633.6362])\n",
      "Epoch 257, Loss: 964.013427734375, y_pred preview: tensor([2545.2417])\n",
      "Epoch 258, Loss: 993.4462280273438, y_pred preview: tensor([2633.6118])\n",
      "Epoch 259, Loss: 964.046142578125, y_pred preview: tensor([2545.2175])\n",
      "Epoch 260, Loss: 993.414306640625, y_pred preview: tensor([2633.5876])\n",
      "Epoch 261, Loss: 964.078369140625, y_pred preview: tensor([2545.1931])\n",
      "Epoch 262, Loss: 993.3814697265625, y_pred preview: tensor([2633.5635])\n",
      "Epoch 263, Loss: 964.1107177734375, y_pred preview: tensor([2545.1689])\n",
      "Epoch 264, Loss: 993.3492431640625, y_pred preview: tensor([2633.5391])\n",
      "Epoch 265, Loss: 964.1431274414062, y_pred preview: tensor([2545.1445])\n",
      "Epoch 266, Loss: 993.3171997070312, y_pred preview: tensor([2633.5149])\n",
      "Epoch 267, Loss: 964.1752319335938, y_pred preview: tensor([2545.1204])\n",
      "Epoch 268, Loss: 993.2850952148438, y_pred preview: tensor([2633.4910])\n",
      "Epoch 269, Loss: 964.2073364257812, y_pred preview: tensor([2545.0964])\n",
      "Epoch 270, Loss: 993.2533569335938, y_pred preview: tensor([2633.4668])\n",
      "Epoch 271, Loss: 964.239013671875, y_pred preview: tensor([2545.0725])\n",
      "Epoch 272, Loss: 993.2213134765625, y_pred preview: tensor([2633.4429])\n",
      "Epoch 273, Loss: 964.2709350585938, y_pred preview: tensor([2545.0483])\n",
      "Epoch 274, Loss: 993.189697265625, y_pred preview: tensor([2633.4189])\n",
      "Epoch 275, Loss: 964.302734375, y_pred preview: tensor([2545.0244])\n",
      "Epoch 276, Loss: 993.15771484375, y_pred preview: tensor([2633.3950])\n",
      "Epoch 277, Loss: 964.33447265625, y_pred preview: tensor([2545.0005])\n",
      "Epoch 278, Loss: 993.12646484375, y_pred preview: tensor([2633.3713])\n",
      "Epoch 279, Loss: 964.3662719726562, y_pred preview: tensor([2544.9768])\n",
      "Epoch 280, Loss: 993.0946044921875, y_pred preview: tensor([2633.3477])\n",
      "Epoch 281, Loss: 964.3976440429688, y_pred preview: tensor([2544.9531])\n",
      "Epoch 282, Loss: 993.063232421875, y_pred preview: tensor([2633.3240])\n",
      "Epoch 283, Loss: 964.4290771484375, y_pred preview: tensor([2544.9294])\n",
      "Epoch 284, Loss: 993.0318603515625, y_pred preview: tensor([2633.3003])\n",
      "Epoch 285, Loss: 964.46044921875, y_pred preview: tensor([2544.9058])\n",
      "Epoch 286, Loss: 993.0006103515625, y_pred preview: tensor([2633.2766])\n",
      "Epoch 287, Loss: 964.4918823242188, y_pred preview: tensor([2544.8821])\n",
      "Epoch 288, Loss: 992.9686889648438, y_pred preview: tensor([2633.2529])\n",
      "Epoch 289, Loss: 964.5234985351562, y_pred preview: tensor([2544.8584])\n",
      "Epoch 290, Loss: 992.937744140625, y_pred preview: tensor([2633.2297])\n",
      "Epoch 291, Loss: 964.55419921875, y_pred preview: tensor([2544.8352])\n",
      "Epoch 292, Loss: 992.90673828125, y_pred preview: tensor([2633.2063])\n",
      "Epoch 293, Loss: 964.5850830078125, y_pred preview: tensor([2544.8118])\n",
      "Epoch 294, Loss: 992.8757934570312, y_pred preview: tensor([2633.1829])\n",
      "Epoch 295, Loss: 964.6163330078125, y_pred preview: tensor([2544.7883])\n",
      "Epoch 296, Loss: 992.8446044921875, y_pred preview: tensor([2633.1594])\n",
      "Epoch 297, Loss: 964.6476440429688, y_pred preview: tensor([2544.7651])\n",
      "Epoch 298, Loss: 992.8134155273438, y_pred preview: tensor([2633.1362])\n",
      "Epoch 299, Loss: 964.6786499023438, y_pred preview: tensor([2544.7417])\n",
      "Epoch 300, Loss: 992.782958984375, y_pred preview: tensor([2633.1130])\n",
      "Epoch 301, Loss: 964.7092895507812, y_pred preview: tensor([2544.7188])\n",
      "Epoch 302, Loss: 992.7523193359375, y_pred preview: tensor([2633.0901])\n",
      "Epoch 303, Loss: 964.7396240234375, y_pred preview: tensor([2544.6956])\n",
      "Epoch 304, Loss: 992.7214965820312, y_pred preview: tensor([2633.0671])\n",
      "Epoch 305, Loss: 964.7703857421875, y_pred preview: tensor([2544.6726])\n",
      "Epoch 306, Loss: 992.691162109375, y_pred preview: tensor([2633.0439])\n",
      "Epoch 307, Loss: 964.8010864257812, y_pred preview: tensor([2544.6494])\n",
      "Epoch 308, Loss: 992.6600952148438, y_pred preview: tensor([2633.0210])\n",
      "Epoch 309, Loss: 964.8322143554688, y_pred preview: tensor([2544.6265])\n",
      "Epoch 310, Loss: 992.6298217773438, y_pred preview: tensor([2632.9978])\n",
      "Epoch 311, Loss: 964.8629150390625, y_pred preview: tensor([2544.6035])\n",
      "Epoch 312, Loss: 992.5992431640625, y_pred preview: tensor([2632.9751])\n",
      "Epoch 313, Loss: 964.8926391601562, y_pred preview: tensor([2544.5808])\n",
      "Epoch 314, Loss: 992.5691528320312, y_pred preview: tensor([2632.9524])\n",
      "Epoch 315, Loss: 964.9230346679688, y_pred preview: tensor([2544.5579])\n",
      "Epoch 316, Loss: 992.5390014648438, y_pred preview: tensor([2632.9297])\n",
      "Epoch 317, Loss: 964.953369140625, y_pred preview: tensor([2544.5352])\n",
      "Epoch 318, Loss: 992.5084228515625, y_pred preview: tensor([2632.9070])\n",
      "Epoch 319, Loss: 964.983154296875, y_pred preview: tensor([2544.5125])\n",
      "Epoch 320, Loss: 992.478271484375, y_pred preview: tensor([2632.8843])\n",
      "Epoch 321, Loss: 965.013671875, y_pred preview: tensor([2544.4897])\n",
      "Epoch 322, Loss: 992.4481811523438, y_pred preview: tensor([2632.8613])\n",
      "Epoch 323, Loss: 965.0441284179688, y_pred preview: tensor([2544.4670])\n",
      "Epoch 324, Loss: 992.41845703125, y_pred preview: tensor([2632.8391])\n",
      "Epoch 325, Loss: 965.0736083984375, y_pred preview: tensor([2544.4446])\n",
      "Epoch 326, Loss: 992.3884887695312, y_pred preview: tensor([2632.8167])\n",
      "Epoch 327, Loss: 965.1036987304688, y_pred preview: tensor([2544.4221])\n",
      "Epoch 328, Loss: 992.3585205078125, y_pred preview: tensor([2632.7942])\n",
      "Epoch 329, Loss: 965.1331176757812, y_pred preview: tensor([2544.3997])\n",
      "Epoch 330, Loss: 992.3287353515625, y_pred preview: tensor([2632.7717])\n",
      "Epoch 331, Loss: 965.1627197265625, y_pred preview: tensor([2544.3772])\n",
      "Epoch 332, Loss: 992.2988891601562, y_pred preview: tensor([2632.7493])\n",
      "Epoch 333, Loss: 965.1930541992188, y_pred preview: tensor([2544.3547])\n",
      "Epoch 334, Loss: 992.2691650390625, y_pred preview: tensor([2632.7268])\n",
      "Epoch 335, Loss: 965.2227172851562, y_pred preview: tensor([2544.3323])\n",
      "Epoch 336, Loss: 992.2398681640625, y_pred preview: tensor([2632.7046])\n",
      "Epoch 337, Loss: 965.2521362304688, y_pred preview: tensor([2544.3103])\n",
      "Epoch 338, Loss: 992.2100830078125, y_pred preview: tensor([2632.6826])\n",
      "Epoch 339, Loss: 965.2820434570312, y_pred preview: tensor([2544.2881])\n",
      "Epoch 340, Loss: 992.1808471679688, y_pred preview: tensor([2632.6604])\n",
      "Epoch 341, Loss: 965.3108520507812, y_pred preview: tensor([2544.2659])\n",
      "Epoch 342, Loss: 992.151611328125, y_pred preview: tensor([2632.6384])\n",
      "Epoch 343, Loss: 965.3408813476562, y_pred preview: tensor([2544.2439])\n",
      "Epoch 344, Loss: 992.1224975585938, y_pred preview: tensor([2632.6162])\n",
      "Epoch 345, Loss: 965.3699951171875, y_pred preview: tensor([2544.2217])\n",
      "Epoch 346, Loss: 992.0928344726562, y_pred preview: tensor([2632.5940])\n",
      "Epoch 347, Loss: 965.3992309570312, y_pred preview: tensor([2544.1997])\n",
      "Epoch 348, Loss: 992.0638427734375, y_pred preview: tensor([2632.5723])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349, Loss: 965.4285278320312, y_pred preview: tensor([2544.1777])\n",
      "Epoch 350, Loss: 992.0347900390625, y_pred preview: tensor([2632.5503])\n",
      "Epoch 351, Loss: 965.4578247070312, y_pred preview: tensor([2544.1560])\n",
      "Epoch 352, Loss: 992.0054931640625, y_pred preview: tensor([2632.5286])\n",
      "Epoch 353, Loss: 965.4863891601562, y_pred preview: tensor([2544.1340])\n",
      "Epoch 354, Loss: 991.9763793945312, y_pred preview: tensor([2632.5068])\n",
      "Epoch 355, Loss: 965.5154418945312, y_pred preview: tensor([2544.1123])\n",
      "Epoch 356, Loss: 991.9476318359375, y_pred preview: tensor([2632.4849])\n",
      "Epoch 357, Loss: 965.54443359375, y_pred preview: tensor([2544.0906])\n",
      "Epoch 358, Loss: 991.9181518554688, y_pred preview: tensor([2632.4631])\n",
      "Epoch 359, Loss: 965.5736694335938, y_pred preview: tensor([2544.0686])\n",
      "Epoch 360, Loss: 991.8897705078125, y_pred preview: tensor([2632.4417])\n",
      "Epoch 361, Loss: 965.6021118164062, y_pred preview: tensor([2544.0471])\n",
      "Epoch 362, Loss: 991.861083984375, y_pred preview: tensor([2632.4202])\n",
      "Epoch 363, Loss: 965.6309204101562, y_pred preview: tensor([2544.0256])\n",
      "Epoch 364, Loss: 991.83251953125, y_pred preview: tensor([2632.3987])\n",
      "Epoch 365, Loss: 965.6595458984375, y_pred preview: tensor([2544.0042])\n",
      "Epoch 366, Loss: 991.803955078125, y_pred preview: tensor([2632.3770])\n",
      "Epoch 367, Loss: 965.687744140625, y_pred preview: tensor([2543.9827])\n",
      "Epoch 368, Loss: 991.7755737304688, y_pred preview: tensor([2632.3555])\n",
      "Epoch 369, Loss: 965.7161865234375, y_pred preview: tensor([2543.9612])\n",
      "Epoch 370, Loss: 991.746826171875, y_pred preview: tensor([2632.3340])\n",
      "Epoch 371, Loss: 965.7451782226562, y_pred preview: tensor([2543.9397])\n",
      "Epoch 372, Loss: 991.7185668945312, y_pred preview: tensor([2632.3127])\n",
      "Epoch 373, Loss: 965.7733764648438, y_pred preview: tensor([2543.9185])\n",
      "Epoch 374, Loss: 991.6904907226562, y_pred preview: tensor([2632.2917])\n",
      "Epoch 375, Loss: 965.8015747070312, y_pred preview: tensor([2543.8972])\n",
      "Epoch 376, Loss: 991.6620483398438, y_pred preview: tensor([2632.2705])\n",
      "Epoch 377, Loss: 965.8300170898438, y_pred preview: tensor([2543.8760])\n",
      "Epoch 378, Loss: 991.6339721679688, y_pred preview: tensor([2632.2493])\n",
      "Epoch 379, Loss: 965.85791015625, y_pred preview: tensor([2543.8547])\n",
      "Epoch 380, Loss: 991.60595703125, y_pred preview: tensor([2632.2280])\n",
      "Epoch 381, Loss: 965.8861083984375, y_pred preview: tensor([2543.8335])\n",
      "Epoch 382, Loss: 991.5775146484375, y_pred preview: tensor([2632.2068])\n",
      "Epoch 383, Loss: 965.914306640625, y_pred preview: tensor([2543.8123])\n",
      "Epoch 384, Loss: 991.5493774414062, y_pred preview: tensor([2632.1855])\n",
      "Epoch 385, Loss: 965.9425659179688, y_pred preview: tensor([2543.7913])\n",
      "Epoch 386, Loss: 991.5213012695312, y_pred preview: tensor([2632.1648])\n",
      "Epoch 387, Loss: 965.969970703125, y_pred preview: tensor([2543.7703])\n",
      "Epoch 388, Loss: 991.4939575195312, y_pred preview: tensor([2632.1438])\n",
      "Epoch 389, Loss: 965.9977416992188, y_pred preview: tensor([2543.7493])\n",
      "Epoch 390, Loss: 991.4660034179688, y_pred preview: tensor([2632.1228])\n",
      "Epoch 391, Loss: 966.0256958007812, y_pred preview: tensor([2543.7285])\n",
      "Epoch 392, Loss: 991.4380493164062, y_pred preview: tensor([2632.1021])\n",
      "Epoch 393, Loss: 966.0535888671875, y_pred preview: tensor([2543.7075])\n",
      "Epoch 394, Loss: 991.4105224609375, y_pred preview: tensor([2632.0811])\n",
      "Epoch 395, Loss: 966.081298828125, y_pred preview: tensor([2543.6868])\n",
      "Epoch 396, Loss: 991.3825073242188, y_pred preview: tensor([2632.0603])\n",
      "Epoch 397, Loss: 966.10888671875, y_pred preview: tensor([2543.6658])\n",
      "Epoch 398, Loss: 991.3551025390625, y_pred preview: tensor([2632.0396])\n",
      "Epoch 399, Loss: 966.1365356445312, y_pred preview: tensor([2543.6453])\n",
      "Epoch 400, Loss: 991.3279418945312, y_pred preview: tensor([2632.0190])\n",
      "Epoch 401, Loss: 966.1638793945312, y_pred preview: tensor([2543.6245])\n",
      "Epoch 402, Loss: 991.3004150390625, y_pred preview: tensor([2631.9985])\n",
      "Epoch 403, Loss: 966.191650390625, y_pred preview: tensor([2543.6040])\n",
      "Epoch 404, Loss: 991.27294921875, y_pred preview: tensor([2631.9778])\n",
      "Epoch 405, Loss: 966.2186889648438, y_pred preview: tensor([2543.5835])\n",
      "Epoch 406, Loss: 991.245849609375, y_pred preview: tensor([2631.9573])\n",
      "Epoch 407, Loss: 966.2461547851562, y_pred preview: tensor([2543.5627])\n",
      "Epoch 408, Loss: 991.218505859375, y_pred preview: tensor([2631.9368])\n",
      "Epoch 409, Loss: 966.2734985351562, y_pred preview: tensor([2543.5422])\n",
      "Epoch 410, Loss: 991.19140625, y_pred preview: tensor([2631.9165])\n",
      "Epoch 411, Loss: 966.30029296875, y_pred preview: tensor([2543.5220])\n",
      "Epoch 412, Loss: 991.1646118164062, y_pred preview: tensor([2631.8960])\n",
      "Epoch 413, Loss: 966.3273315429688, y_pred preview: tensor([2543.5017])\n",
      "Epoch 414, Loss: 991.13720703125, y_pred preview: tensor([2631.8757])\n",
      "Epoch 415, Loss: 966.3543701171875, y_pred preview: tensor([2543.4814])\n",
      "Epoch 416, Loss: 991.1102905273438, y_pred preview: tensor([2631.8555])\n",
      "Epoch 417, Loss: 966.38134765625, y_pred preview: tensor([2543.4612])\n",
      "Epoch 418, Loss: 991.0836791992188, y_pred preview: tensor([2631.8352])\n",
      "Epoch 419, Loss: 966.40869140625, y_pred preview: tensor([2543.4409])\n",
      "Epoch 420, Loss: 991.0563354492188, y_pred preview: tensor([2631.8149])\n",
      "Epoch 421, Loss: 966.43505859375, y_pred preview: tensor([2543.4204])\n",
      "Epoch 422, Loss: 991.0296020507812, y_pred preview: tensor([2631.7947])\n",
      "Epoch 423, Loss: 966.4620361328125, y_pred preview: tensor([2543.4001])\n",
      "Epoch 424, Loss: 991.002685546875, y_pred preview: tensor([2631.7747])\n",
      "Epoch 425, Loss: 966.489013671875, y_pred preview: tensor([2543.3804])\n",
      "Epoch 426, Loss: 990.9761962890625, y_pred preview: tensor([2631.7546])\n",
      "Epoch 427, Loss: 966.5158081054688, y_pred preview: tensor([2543.3604])\n",
      "Epoch 428, Loss: 990.9497680664062, y_pred preview: tensor([2631.7349])\n",
      "Epoch 429, Loss: 966.5419311523438, y_pred preview: tensor([2543.3403])\n",
      "Epoch 430, Loss: 990.9232177734375, y_pred preview: tensor([2631.7148])\n",
      "Epoch 431, Loss: 966.5684204101562, y_pred preview: tensor([2543.3203])\n",
      "Epoch 432, Loss: 990.8963012695312, y_pred preview: tensor([2631.6948])\n",
      "Epoch 433, Loss: 966.5953369140625, y_pred preview: tensor([2543.3003])\n",
      "Epoch 434, Loss: 990.8699951171875, y_pred preview: tensor([2631.6748])\n",
      "Epoch 435, Loss: 966.6217041015625, y_pred preview: tensor([2543.2803])\n",
      "Epoch 436, Loss: 990.8436889648438, y_pred preview: tensor([2631.6548])\n",
      "Epoch 437, Loss: 966.6481323242188, y_pred preview: tensor([2543.2605])\n",
      "Epoch 438, Loss: 990.8174438476562, y_pred preview: tensor([2631.6353])\n",
      "Epoch 439, Loss: 966.6741333007812, y_pred preview: tensor([2543.2407])\n",
      "Epoch 440, Loss: 990.7911987304688, y_pred preview: tensor([2631.6155])\n",
      "Epoch 441, Loss: 966.7006225585938, y_pred preview: tensor([2543.2209])\n",
      "Epoch 442, Loss: 990.7648315429688, y_pred preview: tensor([2631.5959])\n",
      "Epoch 443, Loss: 966.7265625, y_pred preview: tensor([2543.2014])\n",
      "Epoch 444, Loss: 990.7388305664062, y_pred preview: tensor([2631.5762])\n",
      "Epoch 445, Loss: 966.752685546875, y_pred preview: tensor([2543.1816])\n",
      "Epoch 446, Loss: 990.7128295898438, y_pred preview: tensor([2631.5564])\n",
      "Epoch 447, Loss: 966.779052734375, y_pred preview: tensor([2543.1621])\n",
      "Epoch 448, Loss: 990.6865844726562, y_pred preview: tensor([2631.5369])\n",
      "Epoch 449, Loss: 966.804931640625, y_pred preview: tensor([2543.1423])\n",
      "Epoch 450, Loss: 990.6607666015625, y_pred preview: tensor([2631.5176])\n",
      "Epoch 451, Loss: 966.8308715820312, y_pred preview: tensor([2543.1230])\n",
      "Epoch 452, Loss: 990.6349487304688, y_pred preview: tensor([2631.4980])\n",
      "Epoch 453, Loss: 966.8565063476562, y_pred preview: tensor([2543.1038])\n",
      "Epoch 454, Loss: 990.609375, y_pred preview: tensor([2631.4788])\n",
      "Epoch 455, Loss: 966.8822631835938, y_pred preview: tensor([2543.0842])\n",
      "Epoch 456, Loss: 990.5831909179688, y_pred preview: tensor([2631.4595])\n",
      "Epoch 457, Loss: 966.90771484375, y_pred preview: tensor([2543.0649])\n",
      "Epoch 458, Loss: 990.5579833984375, y_pred preview: tensor([2631.4399])\n",
      "Epoch 459, Loss: 966.9335327148438, y_pred preview: tensor([2543.0457])\n",
      "Epoch 460, Loss: 990.5323486328125, y_pred preview: tensor([2631.4207])\n",
      "Epoch 461, Loss: 966.9593505859375, y_pred preview: tensor([2543.0261])\n",
      "Epoch 462, Loss: 990.5064086914062, y_pred preview: tensor([2631.4014])\n",
      "Epoch 463, Loss: 966.9854125976562, y_pred preview: tensor([2543.0068])\n",
      "Epoch 464, Loss: 990.4810180664062, y_pred preview: tensor([2631.3823])\n",
      "Epoch 465, Loss: 967.0106811523438, y_pred preview: tensor([2542.9878])\n",
      "Epoch 466, Loss: 990.4558715820312, y_pred preview: tensor([2631.3633])\n",
      "Epoch 467, Loss: 967.0359497070312, y_pred preview: tensor([2542.9688])\n",
      "Epoch 468, Loss: 990.4305419921875, y_pred preview: tensor([2631.3442])\n",
      "Epoch 469, Loss: 967.0609130859375, y_pred preview: tensor([2542.9497])\n",
      "Epoch 470, Loss: 990.4052124023438, y_pred preview: tensor([2631.3252])\n",
      "Epoch 471, Loss: 967.086181640625, y_pred preview: tensor([2542.9307])\n",
      "Epoch 472, Loss: 990.3794555664062, y_pred preview: tensor([2631.3059])\n",
      "Epoch 473, Loss: 967.1118774414062, y_pred preview: tensor([2542.9116])\n",
      "Epoch 474, Loss: 990.3544311523438, y_pred preview: tensor([2631.2869])\n",
      "Epoch 475, Loss: 967.13720703125, y_pred preview: tensor([2542.8926])\n",
      "Epoch 476, Loss: 990.3289794921875, y_pred preview: tensor([2631.2678])\n",
      "Epoch 477, Loss: 967.1627197265625, y_pred preview: tensor([2542.8735])\n",
      "Epoch 478, Loss: 990.3040771484375, y_pred preview: tensor([2631.2493])\n",
      "Epoch 479, Loss: 967.1873168945312, y_pred preview: tensor([2542.8547])\n",
      "Epoch 480, Loss: 990.2791137695312, y_pred preview: tensor([2631.2305])\n",
      "Epoch 481, Loss: 967.212646484375, y_pred preview: tensor([2542.8359])\n",
      "Epoch 482, Loss: 990.2540893554688, y_pred preview: tensor([2631.2117])\n",
      "Epoch 483, Loss: 967.237060546875, y_pred preview: tensor([2542.8171])\n",
      "Epoch 484, Loss: 990.2288208007812, y_pred preview: tensor([2631.1929])\n",
      "Epoch 485, Loss: 967.2620849609375, y_pred preview: tensor([2542.7986])\n",
      "Epoch 486, Loss: 990.2042846679688, y_pred preview: tensor([2631.1741])\n",
      "Epoch 487, Loss: 967.287353515625, y_pred preview: tensor([2542.7798])\n",
      "Epoch 488, Loss: 990.1793212890625, y_pred preview: tensor([2631.1555])\n",
      "Epoch 489, Loss: 967.3121948242188, y_pred preview: tensor([2542.7610])\n",
      "Epoch 490, Loss: 990.1546020507812, y_pred preview: tensor([2631.1367])\n",
      "Epoch 491, Loss: 967.3370971679688, y_pred preview: tensor([2542.7422])\n",
      "Epoch 492, Loss: 990.1292114257812, y_pred preview: tensor([2631.1179])\n",
      "Epoch 493, Loss: 967.362060546875, y_pred preview: tensor([2542.7234])\n",
      "Epoch 494, Loss: 990.10498046875, y_pred preview: tensor([2631.0996])\n",
      "Epoch 495, Loss: 967.386474609375, y_pred preview: tensor([2542.7051])\n",
      "Epoch 496, Loss: 990.08056640625, y_pred preview: tensor([2631.0811])\n",
      "Epoch 497, Loss: 967.4111938476562, y_pred preview: tensor([2542.6865])\n",
      "Epoch 498, Loss: 990.055908203125, y_pred preview: tensor([2631.0625])\n",
      "Epoch 499, Loss: 967.4353637695312, y_pred preview: tensor([2542.6682])\n",
      "Epoch 500, Loss: 990.031005859375, y_pred preview: tensor([2631.0442])\n",
      "Epoch 501, Loss: 967.4600219726562, y_pred preview: tensor([2542.6497])\n",
      "Epoch 502, Loss: 990.0072021484375, y_pred preview: tensor([2631.0256])\n",
      "Epoch 503, Loss: 967.4846801757812, y_pred preview: tensor([2542.6313])\n",
      "Epoch 504, Loss: 989.982421875, y_pred preview: tensor([2631.0073])\n",
      "Epoch 505, Loss: 967.5092163085938, y_pred preview: tensor([2542.6128])\n",
      "Epoch 506, Loss: 989.9578857421875, y_pred preview: tensor([2630.9888])\n",
      "Epoch 507, Loss: 967.5339965820312, y_pred preview: tensor([2542.5945])\n",
      "Epoch 508, Loss: 989.9336547851562, y_pred preview: tensor([2630.9707])\n",
      "Epoch 509, Loss: 967.5577392578125, y_pred preview: tensor([2542.5762])\n",
      "Epoch 510, Loss: 989.9095458984375, y_pred preview: tensor([2630.9526])\n",
      "Epoch 511, Loss: 967.5816650390625, y_pred preview: tensor([2542.5581])\n",
      "Epoch 512, Loss: 989.8855590820312, y_pred preview: tensor([2630.9346])\n",
      "Epoch 513, Loss: 967.60595703125, y_pred preview: tensor([2542.5400])\n",
      "Epoch 514, Loss: 989.861328125, y_pred preview: tensor([2630.9163])\n",
      "Epoch 515, Loss: 967.6303100585938, y_pred preview: tensor([2542.5220])\n",
      "Epoch 516, Loss: 989.8375854492188, y_pred preview: tensor([2630.8982])\n",
      "Epoch 517, Loss: 967.6542358398438, y_pred preview: tensor([2542.5037])\n",
      "Epoch 518, Loss: 989.81298828125, y_pred preview: tensor([2630.8801])\n",
      "Epoch 519, Loss: 967.67822265625, y_pred preview: tensor([2542.4856])\n",
      "Epoch 520, Loss: 989.7890625, y_pred preview: tensor([2630.8618])\n",
      "Epoch 521, Loss: 967.7022705078125, y_pred preview: tensor([2542.4675])\n",
      "Epoch 522, Loss: 989.76513671875, y_pred preview: tensor([2630.8440])\n",
      "Epoch 523, Loss: 967.7261962890625, y_pred preview: tensor([2542.4497])\n",
      "Epoch 524, Loss: 989.74169921875, y_pred preview: tensor([2630.8262])\n",
      "Epoch 525, Loss: 967.749755859375, y_pred preview: tensor([2542.4319])\n",
      "Epoch 526, Loss: 989.7177124023438, y_pred preview: tensor([2630.8083])\n",
      "Epoch 527, Loss: 967.77392578125, y_pred preview: tensor([2542.4141])\n",
      "Epoch 528, Loss: 989.6943969726562, y_pred preview: tensor([2630.7905])\n",
      "Epoch 529, Loss: 967.7972412109375, y_pred preview: tensor([2542.3962])\n",
      "Epoch 530, Loss: 989.6707763671875, y_pred preview: tensor([2630.7727])\n",
      "Epoch 531, Loss: 967.8211059570312, y_pred preview: tensor([2542.3784])\n",
      "Epoch 532, Loss: 989.6465454101562, y_pred preview: tensor([2630.7549])\n",
      "Epoch 533, Loss: 967.8445434570312, y_pred preview: tensor([2542.3606])\n",
      "Epoch 534, Loss: 989.623291015625, y_pred preview: tensor([2630.7371])\n",
      "Epoch 535, Loss: 967.8682250976562, y_pred preview: tensor([2542.3428])\n",
      "Epoch 536, Loss: 989.5994262695312, y_pred preview: tensor([2630.7197])\n",
      "Epoch 537, Loss: 967.8919677734375, y_pred preview: tensor([2542.3252])\n",
      "Epoch 538, Loss: 989.576416015625, y_pred preview: tensor([2630.7021])\n",
      "Epoch 539, Loss: 967.914794921875, y_pred preview: tensor([2542.3076])\n",
      "Epoch 540, Loss: 989.5530395507812, y_pred preview: tensor([2630.6846])\n",
      "Epoch 541, Loss: 967.9385986328125, y_pred preview: tensor([2542.2900])\n",
      "Epoch 542, Loss: 989.52978515625, y_pred preview: tensor([2630.6670])\n",
      "Epoch 543, Loss: 967.9617309570312, y_pred preview: tensor([2542.2727])\n",
      "Epoch 544, Loss: 989.5066528320312, y_pred preview: tensor([2630.6497])\n",
      "Epoch 545, Loss: 967.9845581054688, y_pred preview: tensor([2542.2551])\n",
      "Epoch 546, Loss: 989.483154296875, y_pred preview: tensor([2630.6321])\n",
      "Epoch 547, Loss: 968.0077514648438, y_pred preview: tensor([2542.2375])\n",
      "Epoch 548, Loss: 989.46044921875, y_pred preview: tensor([2630.6145])\n",
      "Epoch 549, Loss: 968.0313110351562, y_pred preview: tensor([2542.2200])\n",
      "Epoch 550, Loss: 989.4363403320312, y_pred preview: tensor([2630.5969])\n",
      "Epoch 551, Loss: 968.0546875, y_pred preview: tensor([2542.2026])\n",
      "Epoch 552, Loss: 989.4135131835938, y_pred preview: tensor([2630.5796])\n",
      "Epoch 553, Loss: 968.0779418945312, y_pred preview: tensor([2542.1851])\n",
      "Epoch 554, Loss: 989.389892578125, y_pred preview: tensor([2630.5620])\n",
      "Epoch 555, Loss: 968.1017456054688, y_pred preview: tensor([2542.1675])\n",
      "Epoch 556, Loss: 989.36669921875, y_pred preview: tensor([2630.5444])\n",
      "Epoch 557, Loss: 968.1246337890625, y_pred preview: tensor([2542.1499])\n",
      "Epoch 558, Loss: 989.3433837890625, y_pred preview: tensor([2630.5269])\n",
      "Epoch 559, Loss: 968.1481323242188, y_pred preview: tensor([2542.1326])\n",
      "Epoch 560, Loss: 989.3197631835938, y_pred preview: tensor([2630.5095])\n",
      "Epoch 561, Loss: 968.1710815429688, y_pred preview: tensor([2542.1150])\n",
      "Epoch 562, Loss: 989.296875, y_pred preview: tensor([2630.4919])\n",
      "Epoch 563, Loss: 968.1947631835938, y_pred preview: tensor([2542.0974])\n",
      "Epoch 564, Loss: 989.273681640625, y_pred preview: tensor([2630.4744])\n",
      "Epoch 565, Loss: 968.2178955078125, y_pred preview: tensor([2542.0798])\n",
      "Epoch 566, Loss: 989.2503662109375, y_pred preview: tensor([2630.4568])\n",
      "Epoch 567, Loss: 968.2410888671875, y_pred preview: tensor([2542.0625])\n",
      "Epoch 568, Loss: 989.22705078125, y_pred preview: tensor([2630.4395])\n",
      "Epoch 569, Loss: 968.2642822265625, y_pred preview: tensor([2542.0449])\n",
      "Epoch 570, Loss: 989.2037353515625, y_pred preview: tensor([2630.4219])\n",
      "Epoch 571, Loss: 968.2876586914062, y_pred preview: tensor([2542.0273])\n",
      "Epoch 572, Loss: 989.180419921875, y_pred preview: tensor([2630.4043])\n",
      "Epoch 573, Loss: 968.3110961914062, y_pred preview: tensor([2542.0098])\n",
      "Epoch 574, Loss: 989.1571044921875, y_pred preview: tensor([2630.3867])\n",
      "Epoch 575, Loss: 968.3341674804688, y_pred preview: tensor([2541.9924])\n",
      "Epoch 576, Loss: 989.1336669921875, y_pred preview: tensor([2630.3694])\n",
      "Epoch 577, Loss: 968.3572387695312, y_pred preview: tensor([2541.9749])\n",
      "Epoch 578, Loss: 989.1105346679688, y_pred preview: tensor([2630.3518])\n",
      "Epoch 579, Loss: 968.380859375, y_pred preview: tensor([2541.9573])\n",
      "Epoch 580, Loss: 989.087158203125, y_pred preview: tensor([2630.3342])\n",
      "Epoch 581, Loss: 968.4039916992188, y_pred preview: tensor([2541.9397])\n",
      "Epoch 582, Loss: 989.0641479492188, y_pred preview: tensor([2630.3167])\n",
      "Epoch 583, Loss: 968.4273681640625, y_pred preview: tensor([2541.9224])\n",
      "Epoch 584, Loss: 989.040771484375, y_pred preview: tensor([2630.2993])\n",
      "Epoch 585, Loss: 968.4508666992188, y_pred preview: tensor([2541.9048])\n",
      "Epoch 586, Loss: 989.0175170898438, y_pred preview: tensor([2630.2817])\n",
      "Epoch 587, Loss: 968.4735717773438, y_pred preview: tensor([2541.8872])\n",
      "Epoch 588, Loss: 988.9938354492188, y_pred preview: tensor([2630.2642])\n",
      "Epoch 589, Loss: 968.4974365234375, y_pred preview: tensor([2541.8696])\n",
      "Epoch 590, Loss: 988.970458984375, y_pred preview: tensor([2630.2466])\n",
      "Epoch 591, Loss: 968.5206909179688, y_pred preview: tensor([2541.8523])\n",
      "Epoch 592, Loss: 988.947509765625, y_pred preview: tensor([2630.2292])\n",
      "Epoch 593, Loss: 968.5435180664062, y_pred preview: tensor([2541.8347])\n",
      "Epoch 594, Loss: 988.92431640625, y_pred preview: tensor([2630.2117])\n",
      "Epoch 595, Loss: 968.5673217773438, y_pred preview: tensor([2541.8171])\n",
      "Epoch 596, Loss: 988.9014282226562, y_pred preview: tensor([2630.1941])\n",
      "Epoch 597, Loss: 968.5902099609375, y_pred preview: tensor([2541.7996])\n",
      "Epoch 598, Loss: 988.8773193359375, y_pred preview: tensor([2630.1765])\n",
      "Epoch 599, Loss: 968.6138916015625, y_pred preview: tensor([2541.7822])\n",
      "Epoch 600, Loss: 988.8540649414062, y_pred preview: tensor([2630.1592])\n",
      "Epoch 601, Loss: 968.63720703125, y_pred preview: tensor([2541.7646])\n",
      "Epoch 602, Loss: 988.8309326171875, y_pred preview: tensor([2630.1416])\n",
      "Epoch 603, Loss: 968.6604614257812, y_pred preview: tensor([2541.7471])\n",
      "Epoch 604, Loss: 988.8077392578125, y_pred preview: tensor([2630.1240])\n",
      "Epoch 605, Loss: 968.6838989257812, y_pred preview: tensor([2541.7295])\n",
      "Epoch 606, Loss: 988.7847900390625, y_pred preview: tensor([2630.1067])\n",
      "Epoch 607, Loss: 968.7064208984375, y_pred preview: tensor([2541.7124])\n",
      "Epoch 608, Loss: 988.7616577148438, y_pred preview: tensor([2630.0896])\n",
      "Epoch 609, Loss: 968.7293090820312, y_pred preview: tensor([2541.6951])\n",
      "Epoch 610, Loss: 988.7391357421875, y_pred preview: tensor([2630.0725])\n",
      "Epoch 611, Loss: 968.7525024414062, y_pred preview: tensor([2541.6780])\n",
      "Epoch 612, Loss: 988.7161865234375, y_pred preview: tensor([2630.0552])\n",
      "Epoch 613, Loss: 968.775146484375, y_pred preview: tensor([2541.6606])\n",
      "Epoch 614, Loss: 988.6929931640625, y_pred preview: tensor([2630.0381])\n",
      "Epoch 615, Loss: 968.7982177734375, y_pred preview: tensor([2541.6436])\n",
      "Epoch 616, Loss: 988.6702270507812, y_pred preview: tensor([2630.0208])\n",
      "Epoch 617, Loss: 968.8206176757812, y_pred preview: tensor([2541.6262])\n",
      "Epoch 618, Loss: 988.6473388671875, y_pred preview: tensor([2630.0037])\n",
      "Epoch 619, Loss: 968.8436889648438, y_pred preview: tensor([2541.6091])\n",
      "Epoch 620, Loss: 988.624755859375, y_pred preview: tensor([2629.9863])\n",
      "Epoch 621, Loss: 968.86669921875, y_pred preview: tensor([2541.5918])\n",
      "Epoch 622, Loss: 988.601806640625, y_pred preview: tensor([2629.9692])\n",
      "Epoch 623, Loss: 968.8897705078125, y_pred preview: tensor([2541.5747])\n",
      "Epoch 624, Loss: 988.578857421875, y_pred preview: tensor([2629.9519])\n",
      "Epoch 625, Loss: 968.91259765625, y_pred preview: tensor([2541.5574])\n",
      "Epoch 626, Loss: 988.5560302734375, y_pred preview: tensor([2629.9348])\n",
      "Epoch 627, Loss: 968.9351806640625, y_pred preview: tensor([2541.5403])\n",
      "Epoch 628, Loss: 988.532958984375, y_pred preview: tensor([2629.9175])\n",
      "Epoch 629, Loss: 968.9581298828125, y_pred preview: tensor([2541.5229])\n",
      "Epoch 630, Loss: 988.510009765625, y_pred preview: tensor([2629.9004])\n",
      "Epoch 631, Loss: 968.9812622070312, y_pred preview: tensor([2541.5059])\n",
      "Epoch 632, Loss: 988.4871826171875, y_pred preview: tensor([2629.8831])\n",
      "Epoch 633, Loss: 969.00390625, y_pred preview: tensor([2541.4885])\n",
      "Epoch 634, Loss: 988.4639892578125, y_pred preview: tensor([2629.8660])\n",
      "Epoch 635, Loss: 969.027099609375, y_pred preview: tensor([2541.4714])\n",
      "Epoch 636, Loss: 988.4411010742188, y_pred preview: tensor([2629.8486])\n",
      "Epoch 637, Loss: 969.0499267578125, y_pred preview: tensor([2541.4541])\n",
      "Epoch 638, Loss: 988.4187622070312, y_pred preview: tensor([2629.8315])\n",
      "Epoch 639, Loss: 969.0726318359375, y_pred preview: tensor([2541.4370])\n",
      "Epoch 640, Loss: 988.3954467773438, y_pred preview: tensor([2629.8142])\n",
      "Epoch 641, Loss: 969.095458984375, y_pred preview: tensor([2541.4197])\n",
      "Epoch 642, Loss: 988.372314453125, y_pred preview: tensor([2629.7971])\n",
      "Epoch 643, Loss: 969.118408203125, y_pred preview: tensor([2541.4026])\n",
      "Epoch 644, Loss: 988.3499755859375, y_pred preview: tensor([2629.7798])\n",
      "Epoch 645, Loss: 969.1417236328125, y_pred preview: tensor([2541.3853])\n",
      "Epoch 646, Loss: 988.3270874023438, y_pred preview: tensor([2629.7627])\n",
      "Epoch 647, Loss: 969.1640014648438, y_pred preview: tensor([2541.3682])\n",
      "Epoch 648, Loss: 988.3038940429688, y_pred preview: tensor([2629.7454])\n",
      "Epoch 649, Loss: 969.186767578125, y_pred preview: tensor([2541.3508])\n",
      "Epoch 650, Loss: 988.28125, y_pred preview: tensor([2629.7283])\n",
      "Epoch 651, Loss: 969.2098999023438, y_pred preview: tensor([2541.3337])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 652, Loss: 988.258544921875, y_pred preview: tensor([2629.7109])\n",
      "Epoch 653, Loss: 969.2327270507812, y_pred preview: tensor([2541.3164])\n",
      "Epoch 654, Loss: 988.2354736328125, y_pred preview: tensor([2629.6938])\n",
      "Epoch 655, Loss: 969.2557983398438, y_pred preview: tensor([2541.2993])\n",
      "Epoch 656, Loss: 988.2125854492188, y_pred preview: tensor([2629.6765])\n",
      "Epoch 657, Loss: 969.27880859375, y_pred preview: tensor([2541.2820])\n",
      "Epoch 658, Loss: 988.1893920898438, y_pred preview: tensor([2629.6594])\n",
      "Epoch 659, Loss: 969.3016357421875, y_pred preview: tensor([2541.2649])\n",
      "Epoch 660, Loss: 988.166748046875, y_pred preview: tensor([2629.6421])\n",
      "Epoch 661, Loss: 969.3244018554688, y_pred preview: tensor([2541.2476])\n",
      "Epoch 662, Loss: 988.1436767578125, y_pred preview: tensor([2629.6250])\n",
      "Epoch 663, Loss: 969.3471069335938, y_pred preview: tensor([2541.2305])\n",
      "Epoch 664, Loss: 988.1212768554688, y_pred preview: tensor([2629.6077])\n",
      "Epoch 665, Loss: 969.3699340820312, y_pred preview: tensor([2541.2131])\n",
      "Epoch 666, Loss: 988.0979614257812, y_pred preview: tensor([2629.5906])\n",
      "Epoch 667, Loss: 969.3929443359375, y_pred preview: tensor([2541.1960])\n",
      "Epoch 668, Loss: 988.0748291015625, y_pred preview: tensor([2629.5732])\n",
      "Epoch 669, Loss: 969.416015625, y_pred preview: tensor([2541.1787])\n",
      "Epoch 670, Loss: 988.052001953125, y_pred preview: tensor([2629.5562])\n",
      "Epoch 671, Loss: 969.4389038085938, y_pred preview: tensor([2541.1616])\n",
      "Epoch 672, Loss: 988.0291137695312, y_pred preview: tensor([2629.5388])\n",
      "Epoch 673, Loss: 969.4615478515625, y_pred preview: tensor([2541.1445])\n",
      "Epoch 674, Loss: 988.00634765625, y_pred preview: tensor([2629.5217])\n",
      "Epoch 675, Loss: 969.4845581054688, y_pred preview: tensor([2541.1272])\n",
      "Epoch 676, Loss: 987.9834594726562, y_pred preview: tensor([2629.5044])\n",
      "Epoch 677, Loss: 969.50732421875, y_pred preview: tensor([2541.1101])\n",
      "Epoch 678, Loss: 987.960693359375, y_pred preview: tensor([2629.4873])\n",
      "Epoch 679, Loss: 969.5303344726562, y_pred preview: tensor([2541.0928])\n",
      "Epoch 680, Loss: 987.9378051757812, y_pred preview: tensor([2629.4700])\n",
      "Epoch 681, Loss: 969.5530395507812, y_pred preview: tensor([2541.0757])\n",
      "Epoch 682, Loss: 987.9154052734375, y_pred preview: tensor([2629.4529])\n",
      "Epoch 683, Loss: 969.5759887695312, y_pred preview: tensor([2541.0583])\n",
      "Epoch 684, Loss: 987.8922119140625, y_pred preview: tensor([2629.4355])\n",
      "Epoch 685, Loss: 969.59912109375, y_pred preview: tensor([2541.0413])\n",
      "Epoch 686, Loss: 987.869140625, y_pred preview: tensor([2629.4185])\n",
      "Epoch 687, Loss: 969.6218872070312, y_pred preview: tensor([2541.0239])\n",
      "Epoch 688, Loss: 987.8463134765625, y_pred preview: tensor([2629.4011])\n",
      "Epoch 689, Loss: 969.6448974609375, y_pred preview: tensor([2541.0068])\n",
      "Epoch 690, Loss: 987.8234252929688, y_pred preview: tensor([2629.3840])\n",
      "Epoch 691, Loss: 969.667724609375, y_pred preview: tensor([2540.9895])\n",
      "Epoch 692, Loss: 987.8005981445312, y_pred preview: tensor([2629.3667])\n",
      "Epoch 693, Loss: 969.690673828125, y_pred preview: tensor([2540.9724])\n",
      "Epoch 694, Loss: 987.7776489257812, y_pred preview: tensor([2629.3496])\n",
      "Epoch 695, Loss: 969.713623046875, y_pred preview: tensor([2540.9551])\n",
      "Epoch 696, Loss: 987.7547607421875, y_pred preview: tensor([2629.3323])\n",
      "Epoch 697, Loss: 969.7361450195312, y_pred preview: tensor([2540.9380])\n",
      "Epoch 698, Loss: 987.7318725585938, y_pred preview: tensor([2629.3152])\n",
      "Epoch 699, Loss: 969.7589721679688, y_pred preview: tensor([2540.9207])\n",
      "Epoch 700, Loss: 987.7091674804688, y_pred preview: tensor([2629.2979])\n",
      "Epoch 701, Loss: 969.781982421875, y_pred preview: tensor([2540.9036])\n",
      "Epoch 702, Loss: 987.685791015625, y_pred preview: tensor([2629.2808])\n",
      "Epoch 703, Loss: 969.8049926757812, y_pred preview: tensor([2540.8862])\n",
      "Epoch 704, Loss: 987.6624755859375, y_pred preview: tensor([2629.2634])\n",
      "Epoch 705, Loss: 969.8275146484375, y_pred preview: tensor([2540.8691])\n",
      "Epoch 706, Loss: 987.6405639648438, y_pred preview: tensor([2629.2463])\n",
      "Epoch 707, Loss: 969.8507080078125, y_pred preview: tensor([2540.8518])\n",
      "Epoch 708, Loss: 987.6179809570312, y_pred preview: tensor([2629.2295])\n",
      "Epoch 709, Loss: 969.8734130859375, y_pred preview: tensor([2540.8350])\n",
      "Epoch 710, Loss: 987.59521484375, y_pred preview: tensor([2629.2124])\n",
      "Epoch 711, Loss: 969.8958740234375, y_pred preview: tensor([2540.8181])\n",
      "Epoch 712, Loss: 987.5725708007812, y_pred preview: tensor([2629.1956])\n",
      "Epoch 713, Loss: 969.918212890625, y_pred preview: tensor([2540.8010])\n",
      "Epoch 714, Loss: 987.550048828125, y_pred preview: tensor([2629.1787])\n",
      "Epoch 715, Loss: 969.9406127929688, y_pred preview: tensor([2540.7842])\n",
      "Epoch 716, Loss: 987.527587890625, y_pred preview: tensor([2629.1619])\n",
      "Epoch 717, Loss: 969.96337890625, y_pred preview: tensor([2540.7673])\n",
      "Epoch 718, Loss: 987.505615234375, y_pred preview: tensor([2629.1448])\n",
      "Epoch 719, Loss: 969.9857177734375, y_pred preview: tensor([2540.7505])\n",
      "Epoch 720, Loss: 987.4829711914062, y_pred preview: tensor([2629.1279])\n",
      "Epoch 721, Loss: 970.0079956054688, y_pred preview: tensor([2540.7334])\n",
      "Epoch 722, Loss: 987.4603271484375, y_pred preview: tensor([2629.1111])\n",
      "Epoch 723, Loss: 970.0304565429688, y_pred preview: tensor([2540.7166])\n",
      "Epoch 724, Loss: 987.4380493164062, y_pred preview: tensor([2629.0942])\n",
      "Epoch 725, Loss: 970.0531005859375, y_pred preview: tensor([2540.6997])\n",
      "Epoch 726, Loss: 987.4156494140625, y_pred preview: tensor([2629.0771])\n",
      "Epoch 727, Loss: 970.0753784179688, y_pred preview: tensor([2540.6829])\n",
      "Epoch 728, Loss: 987.3931274414062, y_pred preview: tensor([2629.0603])\n",
      "Epoch 729, Loss: 970.09765625, y_pred preview: tensor([2540.6658])\n",
      "Epoch 730, Loss: 987.3709106445312, y_pred preview: tensor([2629.0435])\n",
      "Epoch 731, Loss: 970.1204833984375, y_pred preview: tensor([2540.6489])\n",
      "Epoch 732, Loss: 987.3482055664062, y_pred preview: tensor([2629.0266])\n",
      "Epoch 733, Loss: 970.1429443359375, y_pred preview: tensor([2540.6321])\n",
      "Epoch 734, Loss: 987.3258056640625, y_pred preview: tensor([2629.0095])\n",
      "Epoch 735, Loss: 970.165771484375, y_pred preview: tensor([2540.6152])\n",
      "Epoch 736, Loss: 987.3032836914062, y_pred preview: tensor([2628.9927])\n",
      "Epoch 737, Loss: 970.188232421875, y_pred preview: tensor([2540.5984])\n",
      "Epoch 738, Loss: 987.2804565429688, y_pred preview: tensor([2628.9758])\n",
      "Epoch 739, Loss: 970.21044921875, y_pred preview: tensor([2540.5813])\n",
      "Epoch 740, Loss: 987.2581176757812, y_pred preview: tensor([2628.9590])\n",
      "Epoch 741, Loss: 970.23291015625, y_pred preview: tensor([2540.5645])\n",
      "Epoch 742, Loss: 987.2354125976562, y_pred preview: tensor([2628.9421])\n",
      "Epoch 743, Loss: 970.2552490234375, y_pred preview: tensor([2540.5476])\n",
      "Epoch 744, Loss: 987.2131958007812, y_pred preview: tensor([2628.9250])\n",
      "Epoch 745, Loss: 970.2777099609375, y_pred preview: tensor([2540.5308])\n",
      "Epoch 746, Loss: 987.190673828125, y_pred preview: tensor([2628.9082])\n",
      "Epoch 747, Loss: 970.2999877929688, y_pred preview: tensor([2540.5137])\n",
      "Epoch 748, Loss: 987.1682739257812, y_pred preview: tensor([2628.8914])\n",
      "Epoch 749, Loss: 970.3228759765625, y_pred preview: tensor([2540.4968])\n",
      "Epoch 750, Loss: 987.1458740234375, y_pred preview: tensor([2628.8745])\n",
      "Epoch 751, Loss: 970.3453979492188, y_pred preview: tensor([2540.4800])\n",
      "Epoch 752, Loss: 987.1233520507812, y_pred preview: tensor([2628.8574])\n",
      "Epoch 753, Loss: 970.3677978515625, y_pred preview: tensor([2540.4631])\n",
      "Epoch 754, Loss: 987.1007690429688, y_pred preview: tensor([2628.8406])\n",
      "Epoch 755, Loss: 970.3900756835938, y_pred preview: tensor([2540.4460])\n",
      "Epoch 756, Loss: 987.078369140625, y_pred preview: tensor([2628.8237])\n",
      "Epoch 757, Loss: 970.4127197265625, y_pred preview: tensor([2540.4292])\n",
      "Epoch 758, Loss: 987.0558471679688, y_pred preview: tensor([2628.8069])\n",
      "Epoch 759, Loss: 970.4351806640625, y_pred preview: tensor([2540.4124])\n",
      "Epoch 760, Loss: 987.0331420898438, y_pred preview: tensor([2628.7898])\n",
      "Epoch 761, Loss: 970.4576416015625, y_pred preview: tensor([2540.3955])\n",
      "Epoch 762, Loss: 987.0108032226562, y_pred preview: tensor([2628.7729])\n",
      "Epoch 763, Loss: 970.480224609375, y_pred preview: tensor([2540.3784])\n",
      "Epoch 764, Loss: 986.988037109375, y_pred preview: tensor([2628.7561])\n",
      "Epoch 765, Loss: 970.5023193359375, y_pred preview: tensor([2540.3616])\n",
      "Epoch 766, Loss: 986.9661865234375, y_pred preview: tensor([2628.7393])\n",
      "Epoch 767, Loss: 970.5247802734375, y_pred preview: tensor([2540.3447])\n",
      "Epoch 768, Loss: 986.9435424804688, y_pred preview: tensor([2628.7222])\n",
      "Epoch 769, Loss: 970.5474853515625, y_pred preview: tensor([2540.3279])\n",
      "Epoch 770, Loss: 986.921142578125, y_pred preview: tensor([2628.7053])\n",
      "Epoch 771, Loss: 970.570068359375, y_pred preview: tensor([2540.3110])\n",
      "Epoch 772, Loss: 986.8983764648438, y_pred preview: tensor([2628.6885])\n",
      "Epoch 773, Loss: 970.5924072265625, y_pred preview: tensor([2540.2939])\n",
      "Epoch 774, Loss: 986.8761596679688, y_pred preview: tensor([2628.6716])\n",
      "Epoch 775, Loss: 970.614990234375, y_pred preview: tensor([2540.2771])\n",
      "Epoch 776, Loss: 986.8533325195312, y_pred preview: tensor([2628.6548])\n",
      "Epoch 777, Loss: 970.63720703125, y_pred preview: tensor([2540.2603])\n",
      "Epoch 778, Loss: 986.830810546875, y_pred preview: tensor([2628.6377])\n",
      "Epoch 779, Loss: 970.6597900390625, y_pred preview: tensor([2540.2434])\n",
      "Epoch 780, Loss: 986.80859375, y_pred preview: tensor([2628.6208])\n",
      "Epoch 781, Loss: 970.6824951171875, y_pred preview: tensor([2540.2263])\n",
      "Epoch 782, Loss: 986.78662109375, y_pred preview: tensor([2628.6040])\n",
      "Epoch 783, Loss: 970.7048950195312, y_pred preview: tensor([2540.2095])\n",
      "Epoch 784, Loss: 986.7636108398438, y_pred preview: tensor([2628.5872])\n",
      "Epoch 785, Loss: 970.7269287109375, y_pred preview: tensor([2540.1926])\n",
      "Epoch 786, Loss: 986.7413330078125, y_pred preview: tensor([2628.5701])\n",
      "Epoch 787, Loss: 970.7496948242188, y_pred preview: tensor([2540.1758])\n",
      "Epoch 788, Loss: 986.7185668945312, y_pred preview: tensor([2628.5532])\n",
      "Epoch 789, Loss: 970.7722778320312, y_pred preview: tensor([2540.1587])\n",
      "Epoch 790, Loss: 986.6964721679688, y_pred preview: tensor([2628.5364])\n",
      "Epoch 791, Loss: 970.79443359375, y_pred preview: tensor([2540.1418])\n",
      "Epoch 792, Loss: 986.6737670898438, y_pred preview: tensor([2628.5195])\n",
      "Epoch 793, Loss: 970.8169555664062, y_pred preview: tensor([2540.1250])\n",
      "Epoch 794, Loss: 986.651123046875, y_pred preview: tensor([2628.5024])\n",
      "Epoch 795, Loss: 970.839599609375, y_pred preview: tensor([2540.1082])\n",
      "Epoch 796, Loss: 986.6285400390625, y_pred preview: tensor([2628.4856])\n",
      "Epoch 797, Loss: 970.8622436523438, y_pred preview: tensor([2540.0911])\n",
      "Epoch 798, Loss: 986.6063842773438, y_pred preview: tensor([2628.4688])\n",
      "Epoch 799, Loss: 970.8844604492188, y_pred preview: tensor([2540.0742])\n",
      "Epoch 800, Loss: 986.5836791992188, y_pred preview: tensor([2628.4519])\n",
      "Epoch 801, Loss: 970.906982421875, y_pred preview: tensor([2540.0574])\n",
      "Epoch 802, Loss: 986.5613403320312, y_pred preview: tensor([2628.4348])\n",
      "Epoch 803, Loss: 970.9295043945312, y_pred preview: tensor([2540.0405])\n",
      "Epoch 804, Loss: 986.538818359375, y_pred preview: tensor([2628.4180])\n",
      "Epoch 805, Loss: 970.951904296875, y_pred preview: tensor([2540.0237])\n",
      "Epoch 806, Loss: 986.5164184570312, y_pred preview: tensor([2628.4011])\n",
      "Epoch 807, Loss: 970.9745483398438, y_pred preview: tensor([2540.0066])\n",
      "Epoch 808, Loss: 986.4942016601562, y_pred preview: tensor([2628.3845])\n",
      "Epoch 809, Loss: 970.9964599609375, y_pred preview: tensor([2539.9900])\n",
      "Epoch 810, Loss: 986.471923828125, y_pred preview: tensor([2628.3679])\n",
      "Epoch 811, Loss: 971.018798828125, y_pred preview: tensor([2539.9734])\n",
      "Epoch 812, Loss: 986.4500122070312, y_pred preview: tensor([2628.3513])\n",
      "Epoch 813, Loss: 971.0407104492188, y_pred preview: tensor([2539.9568])\n",
      "Epoch 814, Loss: 986.42822265625, y_pred preview: tensor([2628.3347])\n",
      "Epoch 815, Loss: 971.0630493164062, y_pred preview: tensor([2539.9402])\n",
      "Epoch 816, Loss: 986.4063110351562, y_pred preview: tensor([2628.3181])\n",
      "Epoch 817, Loss: 971.0848388671875, y_pred preview: tensor([2539.9236])\n",
      "Epoch 818, Loss: 986.3839721679688, y_pred preview: tensor([2628.3015])\n",
      "Epoch 819, Loss: 971.1063842773438, y_pred preview: tensor([2539.9070])\n",
      "Epoch 820, Loss: 986.3616943359375, y_pred preview: tensor([2628.2849])\n",
      "Epoch 821, Loss: 971.129150390625, y_pred preview: tensor([2539.8904])\n",
      "Epoch 822, Loss: 986.3397827148438, y_pred preview: tensor([2628.2683])\n",
      "Epoch 823, Loss: 971.1512451171875, y_pred preview: tensor([2539.8738])\n",
      "Epoch 824, Loss: 986.3174438476562, y_pred preview: tensor([2628.2517])\n",
      "Epoch 825, Loss: 971.1729736328125, y_pred preview: tensor([2539.8574])\n",
      "Epoch 826, Loss: 986.2954711914062, y_pred preview: tensor([2628.2351])\n",
      "Epoch 827, Loss: 971.1953125, y_pred preview: tensor([2539.8408])\n",
      "Epoch 828, Loss: 986.2733764648438, y_pred preview: tensor([2628.2185])\n",
      "Epoch 829, Loss: 971.217041015625, y_pred preview: tensor([2539.8242])\n",
      "Epoch 830, Loss: 986.2514038085938, y_pred preview: tensor([2628.2019])\n",
      "Epoch 831, Loss: 971.2391357421875, y_pred preview: tensor([2539.8076])\n",
      "Epoch 832, Loss: 986.2293090820312, y_pred preview: tensor([2628.1853])\n",
      "Epoch 833, Loss: 971.2614135742188, y_pred preview: tensor([2539.7910])\n",
      "Epoch 834, Loss: 986.2072143554688, y_pred preview: tensor([2628.1687])\n",
      "Epoch 835, Loss: 971.2832641601562, y_pred preview: tensor([2539.7744])\n",
      "Epoch 836, Loss: 986.1851806640625, y_pred preview: tensor([2628.1521])\n",
      "Epoch 837, Loss: 971.3052978515625, y_pred preview: tensor([2539.7578])\n",
      "Epoch 838, Loss: 986.1630249023438, y_pred preview: tensor([2628.1355])\n",
      "Epoch 839, Loss: 971.3277587890625, y_pred preview: tensor([2539.7412])\n",
      "Epoch 840, Loss: 986.1411743164062, y_pred preview: tensor([2628.1189])\n",
      "Epoch 841, Loss: 971.349609375, y_pred preview: tensor([2539.7246])\n",
      "Epoch 842, Loss: 986.118896484375, y_pred preview: tensor([2628.1023])\n",
      "Epoch 843, Loss: 971.3713989257812, y_pred preview: tensor([2539.7080])\n",
      "Epoch 844, Loss: 986.0964965820312, y_pred preview: tensor([2628.0857])\n",
      "Epoch 845, Loss: 971.3936157226562, y_pred preview: tensor([2539.6914])\n",
      "Epoch 846, Loss: 986.074951171875, y_pred preview: tensor([2628.0691])\n",
      "Epoch 847, Loss: 971.4157104492188, y_pred preview: tensor([2539.6748])\n",
      "Epoch 848, Loss: 986.052734375, y_pred preview: tensor([2628.0525])\n",
      "Epoch 849, Loss: 971.4378051757812, y_pred preview: tensor([2539.6582])\n",
      "Epoch 850, Loss: 986.0306396484375, y_pred preview: tensor([2628.0359])\n",
      "Epoch 851, Loss: 971.4600219726562, y_pred preview: tensor([2539.6416])\n",
      "Epoch 852, Loss: 986.0088500976562, y_pred preview: tensor([2628.0195])\n",
      "Epoch 853, Loss: 971.4820556640625, y_pred preview: tensor([2539.6250])\n",
      "Epoch 854, Loss: 985.9865112304688, y_pred preview: tensor([2628.0029])\n",
      "Epoch 855, Loss: 971.5042724609375, y_pred preview: tensor([2539.6084])\n",
      "Epoch 856, Loss: 985.9646606445312, y_pred preview: tensor([2627.9863])\n",
      "Epoch 857, Loss: 971.5263061523438, y_pred preview: tensor([2539.5918])\n",
      "Epoch 858, Loss: 985.9424438476562, y_pred preview: tensor([2627.9697])\n",
      "Epoch 859, Loss: 971.5479736328125, y_pred preview: tensor([2539.5752])\n",
      "Epoch 860, Loss: 985.9201049804688, y_pred preview: tensor([2627.9531])\n",
      "Epoch 861, Loss: 971.5703125, y_pred preview: tensor([2539.5586])\n",
      "Epoch 862, Loss: 985.8984375, y_pred preview: tensor([2627.9365])\n",
      "Epoch 863, Loss: 971.592529296875, y_pred preview: tensor([2539.5420])\n",
      "Epoch 864, Loss: 985.8766479492188, y_pred preview: tensor([2627.9199])\n",
      "Epoch 865, Loss: 971.6146240234375, y_pred preview: tensor([2539.5254])\n",
      "Epoch 866, Loss: 985.8540649414062, y_pred preview: tensor([2627.9033])\n",
      "Epoch 867, Loss: 971.63623046875, y_pred preview: tensor([2539.5088])\n",
      "Epoch 868, Loss: 985.832275390625, y_pred preview: tensor([2627.8867])\n",
      "Epoch 869, Loss: 971.65869140625, y_pred preview: tensor([2539.4922])\n",
      "Epoch 870, Loss: 985.8099975585938, y_pred preview: tensor([2627.8701])\n",
      "Epoch 871, Loss: 971.6802368164062, y_pred preview: tensor([2539.4756])\n",
      "Epoch 872, Loss: 985.787841796875, y_pred preview: tensor([2627.8535])\n",
      "Epoch 873, Loss: 971.7022705078125, y_pred preview: tensor([2539.4590])\n",
      "Epoch 874, Loss: 985.765625, y_pred preview: tensor([2627.8369])\n",
      "Epoch 875, Loss: 971.7249755859375, y_pred preview: tensor([2539.4424])\n",
      "Epoch 876, Loss: 985.7438354492188, y_pred preview: tensor([2627.8203])\n",
      "Epoch 877, Loss: 971.7468872070312, y_pred preview: tensor([2539.4258])\n",
      "Epoch 878, Loss: 985.7215576171875, y_pred preview: tensor([2627.8037])\n",
      "Epoch 879, Loss: 971.7689208984375, y_pred preview: tensor([2539.4092])\n",
      "Epoch 880, Loss: 985.6995849609375, y_pred preview: tensor([2627.7871])\n",
      "Epoch 881, Loss: 971.7909545898438, y_pred preview: tensor([2539.3926])\n",
      "Epoch 882, Loss: 985.677490234375, y_pred preview: tensor([2627.7705])\n",
      "Epoch 883, Loss: 971.8125, y_pred preview: tensor([2539.3760])\n",
      "Epoch 884, Loss: 985.655517578125, y_pred preview: tensor([2627.7539])\n",
      "Epoch 885, Loss: 971.8351440429688, y_pred preview: tensor([2539.3594])\n",
      "Epoch 886, Loss: 985.6334228515625, y_pred preview: tensor([2627.7373])\n",
      "Epoch 887, Loss: 971.8573608398438, y_pred preview: tensor([2539.3428])\n",
      "Epoch 888, Loss: 985.611328125, y_pred preview: tensor([2627.7207])\n",
      "Epoch 889, Loss: 971.8792724609375, y_pred preview: tensor([2539.3262])\n",
      "Epoch 890, Loss: 985.58935546875, y_pred preview: tensor([2627.7041])\n",
      "Epoch 891, Loss: 971.9014892578125, y_pred preview: tensor([2539.3096])\n",
      "Epoch 892, Loss: 985.5671997070312, y_pred preview: tensor([2627.6875])\n",
      "Epoch 893, Loss: 971.923095703125, y_pred preview: tensor([2539.2930])\n",
      "Epoch 894, Loss: 985.5452270507812, y_pred preview: tensor([2627.6709])\n",
      "Epoch 895, Loss: 971.9452514648438, y_pred preview: tensor([2539.2764])\n",
      "Epoch 896, Loss: 985.523193359375, y_pred preview: tensor([2627.6543])\n",
      "Epoch 897, Loss: 971.9678344726562, y_pred preview: tensor([2539.2598])\n",
      "Epoch 898, Loss: 985.5011596679688, y_pred preview: tensor([2627.6377])\n",
      "Epoch 899, Loss: 971.9894409179688, y_pred preview: tensor([2539.2432])\n",
      "Epoch 900, Loss: 985.4785766601562, y_pred preview: tensor([2627.6211])\n",
      "Epoch 901, Loss: 972.0115356445312, y_pred preview: tensor([2539.2266])\n",
      "Epoch 902, Loss: 985.4568481445312, y_pred preview: tensor([2627.6045])\n",
      "Epoch 903, Loss: 972.0337524414062, y_pred preview: tensor([2539.2100])\n",
      "Epoch 904, Loss: 985.434814453125, y_pred preview: tensor([2627.5879])\n",
      "Epoch 905, Loss: 972.055419921875, y_pred preview: tensor([2539.1934])\n",
      "Epoch 906, Loss: 985.41259765625, y_pred preview: tensor([2627.5713])\n",
      "Epoch 907, Loss: 972.0780639648438, y_pred preview: tensor([2539.1768])\n",
      "Epoch 908, Loss: 985.3909912109375, y_pred preview: tensor([2627.5547])\n",
      "Epoch 909, Loss: 972.0999145507812, y_pred preview: tensor([2539.1602])\n",
      "Epoch 910, Loss: 985.368408203125, y_pred preview: tensor([2627.5381])\n",
      "Epoch 911, Loss: 972.1220092773438, y_pred preview: tensor([2539.1436])\n",
      "Epoch 912, Loss: 985.3471069335938, y_pred preview: tensor([2627.5217])\n",
      "Epoch 913, Loss: 972.1434936523438, y_pred preview: tensor([2539.1274])\n",
      "Epoch 914, Loss: 985.3253173828125, y_pred preview: tensor([2627.5056])\n",
      "Epoch 915, Loss: 972.16552734375, y_pred preview: tensor([2539.1111])\n",
      "Epoch 916, Loss: 985.3035888671875, y_pred preview: tensor([2627.4893])\n",
      "Epoch 917, Loss: 972.1869506835938, y_pred preview: tensor([2539.0947])\n",
      "Epoch 918, Loss: 985.2820434570312, y_pred preview: tensor([2627.4729])\n",
      "Epoch 919, Loss: 972.208740234375, y_pred preview: tensor([2539.0786])\n",
      "Epoch 920, Loss: 985.2603759765625, y_pred preview: tensor([2627.4568])\n",
      "Epoch 921, Loss: 972.230224609375, y_pred preview: tensor([2539.0623])\n",
      "Epoch 922, Loss: 985.23876953125, y_pred preview: tensor([2627.4404])\n",
      "Epoch 923, Loss: 972.251953125, y_pred preview: tensor([2539.0459])\n",
      "Epoch 924, Loss: 985.2171630859375, y_pred preview: tensor([2627.4241])\n",
      "Epoch 925, Loss: 972.273681640625, y_pred preview: tensor([2539.0295])\n",
      "Epoch 926, Loss: 985.1956176757812, y_pred preview: tensor([2627.4077])\n",
      "Epoch 927, Loss: 972.2951049804688, y_pred preview: tensor([2539.0134])\n",
      "Epoch 928, Loss: 985.1737670898438, y_pred preview: tensor([2627.3916])\n",
      "Epoch 929, Loss: 972.3169555664062, y_pred preview: tensor([2538.9971])\n",
      "Epoch 930, Loss: 985.15185546875, y_pred preview: tensor([2627.3752])\n",
      "Epoch 931, Loss: 972.338623046875, y_pred preview: tensor([2538.9807])\n",
      "Epoch 932, Loss: 985.1306762695312, y_pred preview: tensor([2627.3589])\n",
      "Epoch 933, Loss: 972.360107421875, y_pred preview: tensor([2538.9646])\n",
      "Epoch 934, Loss: 985.10888671875, y_pred preview: tensor([2627.3428])\n",
      "Epoch 935, Loss: 972.382080078125, y_pred preview: tensor([2538.9482])\n",
      "Epoch 936, Loss: 985.087158203125, y_pred preview: tensor([2627.3264])\n",
      "Epoch 937, Loss: 972.4032592773438, y_pred preview: tensor([2538.9319])\n",
      "Epoch 938, Loss: 985.0653686523438, y_pred preview: tensor([2627.3101])\n",
      "Epoch 939, Loss: 972.4252319335938, y_pred preview: tensor([2538.9155])\n",
      "Epoch 940, Loss: 985.0443725585938, y_pred preview: tensor([2627.2937])\n",
      "Epoch 941, Loss: 972.44677734375, y_pred preview: tensor([2538.8994])\n",
      "Epoch 942, Loss: 985.021728515625, y_pred preview: tensor([2627.2776])\n",
      "Epoch 943, Loss: 972.4689331054688, y_pred preview: tensor([2538.8831])\n",
      "Epoch 944, Loss: 985.0003051757812, y_pred preview: tensor([2627.2612])\n",
      "Epoch 945, Loss: 972.4899291992188, y_pred preview: tensor([2538.8667])\n",
      "Epoch 946, Loss: 984.9790649414062, y_pred preview: tensor([2627.2449])\n",
      "Epoch 947, Loss: 972.5115356445312, y_pred preview: tensor([2538.8506])\n",
      "Epoch 948, Loss: 984.9568481445312, y_pred preview: tensor([2627.2288])\n",
      "Epoch 949, Loss: 972.53369140625, y_pred preview: tensor([2538.8342])\n",
      "Epoch 950, Loss: 984.935546875, y_pred preview: tensor([2627.2124])\n",
      "Epoch 951, Loss: 972.5552368164062, y_pred preview: tensor([2538.8179])\n",
      "Epoch 952, Loss: 984.913330078125, y_pred preview: tensor([2627.1960])\n",
      "Epoch 953, Loss: 972.5769653320312, y_pred preview: tensor([2538.8015])\n",
      "Epoch 954, Loss: 984.8920288085938, y_pred preview: tensor([2627.1797])\n",
      "Epoch 955, Loss: 972.5985717773438, y_pred preview: tensor([2538.7854])\n",
      "Epoch 956, Loss: 984.870361328125, y_pred preview: tensor([2627.1636])\n",
      "Epoch 957, Loss: 972.6202392578125, y_pred preview: tensor([2538.7690])\n",
      "Epoch 958, Loss: 984.8485107421875, y_pred preview: tensor([2627.1472])\n",
      "Epoch 959, Loss: 972.6416625976562, y_pred preview: tensor([2538.7527])\n",
      "Epoch 960, Loss: 984.8272094726562, y_pred preview: tensor([2627.1309])\n",
      "Epoch 961, Loss: 972.663330078125, y_pred preview: tensor([2538.7366])\n",
      "Epoch 962, Loss: 984.805419921875, y_pred preview: tensor([2627.1145])\n",
      "Epoch 963, Loss: 972.68505859375, y_pred preview: tensor([2538.7202])\n",
      "Epoch 964, Loss: 984.7838134765625, y_pred preview: tensor([2627.0984])\n",
      "Epoch 965, Loss: 972.7066650390625, y_pred preview: tensor([2538.7039])\n",
      "Epoch 966, Loss: 984.7620849609375, y_pred preview: tensor([2627.0820])\n",
      "Epoch 967, Loss: 972.7283325195312, y_pred preview: tensor([2538.6875])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 968, Loss: 984.7402954101562, y_pred preview: tensor([2627.0657])\n",
      "Epoch 969, Loss: 972.7496948242188, y_pred preview: tensor([2538.6714])\n",
      "Epoch 970, Loss: 984.7189331054688, y_pred preview: tensor([2627.0496])\n",
      "Epoch 971, Loss: 972.771728515625, y_pred preview: tensor([2538.6550])\n",
      "Epoch 972, Loss: 984.6970825195312, y_pred preview: tensor([2627.0332])\n",
      "Epoch 973, Loss: 972.7932739257812, y_pred preview: tensor([2538.6387])\n",
      "Epoch 974, Loss: 984.6754150390625, y_pred preview: tensor([2627.0168])\n",
      "Epoch 975, Loss: 972.8152465820312, y_pred preview: tensor([2538.6226])\n",
      "Epoch 976, Loss: 984.6536865234375, y_pred preview: tensor([2627.0005])\n",
      "Epoch 977, Loss: 972.8369750976562, y_pred preview: tensor([2538.6062])\n",
      "Epoch 978, Loss: 984.6318969726562, y_pred preview: tensor([2626.9844])\n",
      "Epoch 979, Loss: 972.858154296875, y_pred preview: tensor([2538.5898])\n",
      "Epoch 980, Loss: 984.6105346679688, y_pred preview: tensor([2626.9680])\n",
      "Epoch 981, Loss: 972.8799438476562, y_pred preview: tensor([2538.5735])\n",
      "Epoch 982, Loss: 984.5889892578125, y_pred preview: tensor([2626.9517])\n",
      "Epoch 983, Loss: 972.9017944335938, y_pred preview: tensor([2538.5574])\n",
      "Epoch 984, Loss: 984.5672607421875, y_pred preview: tensor([2626.9355])\n",
      "Epoch 985, Loss: 972.9232788085938, y_pred preview: tensor([2538.5410])\n",
      "Epoch 986, Loss: 984.5457153320312, y_pred preview: tensor([2626.9192])\n",
      "Epoch 987, Loss: 972.9450073242188, y_pred preview: tensor([2538.5247])\n",
      "Epoch 988, Loss: 984.52392578125, y_pred preview: tensor([2626.9028])\n",
      "Epoch 989, Loss: 972.966552734375, y_pred preview: tensor([2538.5083])\n",
      "Epoch 990, Loss: 984.5020141601562, y_pred preview: tensor([2626.8865])\n",
      "Epoch 991, Loss: 972.9884643554688, y_pred preview: tensor([2538.4922])\n",
      "Epoch 992, Loss: 984.4806518554688, y_pred preview: tensor([2626.8704])\n",
      "Epoch 993, Loss: 973.0100708007812, y_pred preview: tensor([2538.4758])\n",
      "Epoch 994, Loss: 984.4586181640625, y_pred preview: tensor([2626.8540])\n",
      "Epoch 995, Loss: 973.031494140625, y_pred preview: tensor([2538.4595])\n",
      "Epoch 996, Loss: 984.4368896484375, y_pred preview: tensor([2626.8376])\n",
      "Epoch 997, Loss: 973.05322265625, y_pred preview: tensor([2538.4434])\n",
      "Epoch 998, Loss: 984.4154663085938, y_pred preview: tensor([2626.8215])\n",
      "Epoch 999, Loss: 973.0745849609375, y_pred preview: tensor([2538.4270])\n",
      "Train Loss: 984.3937377929688\n",
      "Test Losss: 3260.69873046875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(984.3937), tensor(3260.6987))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train linear regression\n",
    "assessor_config =  config['assessor']\n",
    "assessor_config['linear_regression']['epochs'] = 1000\n",
    "assessor = HomeAssessor(assessor_config)\n",
    "\n",
    "calculate_train_val_loss(assessor, train_x_split, train_y_split, test_x_split, test_y_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train nn module\n",
    "assessor_config =  config['assessor']\n",
    "assessor_config['simple_nn']['epochs'] = 10\n",
    "assessor_config['model'] = 'simple_nn'\n",
    "assessor = HomeAssessor(assessor_config)\n",
    "\n",
    "calculate_train_val_loss(assessor, train_x_split, train_y_split, test_x_split, test_y_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
